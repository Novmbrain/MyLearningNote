# 计网：自顶向下

# 第一章：Introduction

![image-20210710153535247](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210710153535247.png)

**端系统**

端系统（End System）通过通信链路（Communication links）和分组交换机（packet switch）连接到一起。

有非常多种通信链路：同轴线缆、铜线、光缆等。不同的链路能够以不同的速率（transmission rate）进行传输数据。链路的传输速率 bit/s 或者 bps

当一个段系统要向另一个段系统发送数据时，发送端会将数据分段并给段都加上一个首部字节（header bytes）。由此形成的信息包被称为分组（packet）这些分组通过网络发送到目的地的端系统，然后在那里被组装成原始数据

端系统也称为主机（host）

**分组交换机（packet switch ）**

分组交换机从它的一条输入的通信链路接受分组，然后讲其转发到一个输出的通信链路。主要的分组交换机有两种

- 路由器（router）：通常用于网络核心（network core）
- 链路层交换机（Link-layer switch）：通常用于接入网（access networks）

 从发送端系统到接收端系统，一个分组所经历的一系列通信链路和分组交换机称为通 过该网络的路径( route 或 path) 

**因特网服务提供商（Internet Service Provider）**

端系统通过因特网服务提供商 (Internet Service Provider, ISP) 接人因特网。每个 ISP 是一个由多个分组交换机和多段通信 链路组成的网络。 各 ISP 为端系统提供了各种不同类型的网络接人

 因特网就是 将端系统彼此互联，因此为端系统提供接人的 ISP 也必须互联。 低层的 ISP 通过国家的 国际的高层 ISP  互联起来。 高层 ISP 是由通过高速光纤链路互联的高速路由器组成的。 无论是高层还是低层 ISP 网络，它们每 个都是独立管理的，运行着 E 协议(详情见后) ，遵从一定的命名和地址习惯。 

**协议（Protocol）**

TCP协议（Transmission Control Protocol）和 IP协议（Internet Protocol）是两个主要的互联网协议。因特网的主要协议统称为 TCP/IP。 

**接入网（Access Networks）**

![image-20210710163713225](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210710163713225.png)

接入网 ( access network) ，这是指将端系统连接到其边缘路囱器( edge router) 的物理链路。 边缘路由器是端系统到任何其他远程端系统的路径上的第一台路由器。

家庭接入：

- 数字用户线（Digital subscriber line）：通常用户从和提供本地电话服务相同的公司出获得DSL 网络接入 。每个用户的 DSL 调制解调器使用现有的电话线(双绞铜线，将在 1.2.2 节中讨论)与位于本地电话公司的 本地中心局 (CO) 中的数字用户线接入复用器 (DSLAM) 来交换数据。 家庭的 DSL 调制 解调器得到数字数据后将其转换为高频音，以通过电话线传输给本地中心局;来自许多家 庭的模拟信号在 DSLAM 处被转换回数字形式。

![image-20210710165923554](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210710165923554.png)

- 电缆：缆因特网接入 (cable lnlemet access) 利用了有线电视公司现有的有线电视基础设施

企业家庭接入：

在公司和大学校园以及在越来越多的家庭环境中，通常是用局域网 (LAN) 将端用户 连接到边缘路由器

- 以太网：以太网用户使用双绞铜线 与一台以太网交换机相连

![image-20210710171433287](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210710171433287.png)

## 网络核心

在考察了因特网边缘后，我们现在更深入地研究网络核心，即由互联因特网端系统的 分组交换机和链路构成的网状网络。

![image-20210710172815741](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210710172815741.png)

## 分组交换

在各种网络应用中，端系统彼此交换报文( message) 。 

为了从端系统向目的端系统发送一个报文，源将长报文划分为较小的数据块，称之为分组( packet) 。 在源和 目的之间，每个分组都通过通信链路和分组交换机 (packet switch) (交换机主要有两类: 路由器和链路层交换机)传送。

分组以等于该链路最大传输速率的速度传输通过通信链 路。 因此，如果某源端系统或分组交换机经过-条链路发送一个 L 比特的分组，链路的传 输速率为 R 比特/秒，则传输该分组的时间为 L/R 秒。

###  存储转发传输 

多数分组交换机在链路的输入端使用存储转发传输( store-and-forward transmission) 。存储转发机制是指在交换机能够开始向输出链路传输该分组的第一个比特之前，必须接收到整个分组。

![image-20210710173725411](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210710173725411.png)

我们现在来考虑通过由 N 条速率均为 R 的链路组成的路径(所以，在源和目的地之 间有飞N - 1个路由器) ，从源到目的地发送一个分组的总体情况。 应用如上相同的逻辑，我 们看到端到端时延是: 

![image-20210710185413757](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210710185413757.png)

### 排队时延和分组丢失

![image-20210710190103515](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210710190103515.png)

每个分组交换机有多条链路与之相连。 对于每条相连的链路，该分组交换机具有一个 输出缓存 (output buffer) (也称为输出队列 output queue) ，它用于存储路由器准备发往那 条链路的分组。 。如果到达的分组需要传输到某 条链路，但发现该链路正忙于传输其他分组，该到达分组必须在该输出缓存中等待。

除了存储转发时延以外，分组还要承受输出缓存的排队时延 (queue delay) 。 这些时延是变化的，变化的程度取决于网络中的拥塞程度。 因为缓存空间的大小是有限的， 一个到达的分组可能发现该缓存已被其他等待传输的分组完全充满了。 在此情况下，将出现分 组丢失(丢包) (packet lost) ，到达的分组或已经排队的分组之一将被丢弃 



## 转发表和路由选择协议

转发表和路由选择协议（Forwarding Tables and Routing Protocols）

路由器从与它相连的一条通信链路得到分组，将其向与它相连的另一 条通信链路转发。 但是该路由器怎样决定它应当向哪条链路进行转发呢?不同的计算机网 络实际上是以不同的方式完成的。 这里，我们简要介绍在因特网所采用的方法

在因特网中，每个端系统具有一个称为 IP 地址的地址。 当源主机要向目的端系统发 送一个分组时，源在该分组的首部包含了目的地的 地址。 

每台路由器具有一个转发表 (forwarding table) ，用于将目的地址(或目的地址的一部分)映射成为输出链路。 当某分组到达一台路由器时，路由器检查该地址，并用这个目的地址搜索其转发表，以发现适当的出链路。 路由器则将分组导向该出链路。 

## 电路交换

- 在电路交换网络中，在端系统间通信会话期间，预留了端系统间通信沿路径所需要的 资源(缓存，链路传输速率) 。 

- 在分组交换网络中，这些资源则不是预留的;会话的报文 按需使用这些资源，其后果可能是不得不等待(即排队)接人通信线路。

电路交换：在发送方能够发送信息之前，该网络必须在发送方和接收方之间建立一条连接。 此时沿着发送方和接收方之间路径上的交换机都将为该连接维护连接状态。用电话的术语来说，该连接被称为一条电路 ( circuit) 。 当网络创建这种电路时，它也在连接期间在该网络链路上预留了恒定的传输速 率(表示为每条链路传输容量的一部分) 。 既然已经为该发送方-接收方连接预留了带宽，则发送方能够以确保的恒定速率向接收方传送数据。

## 网络的网络

总结一下，今天的因特网是一个网络的网络，其结构复杂，由卡多个第一层 ISP 和数 十万个较低层 ISP 组成。 ISP 覆盖的区域有所不同，有些跨越多个大洲和大洋，有些限于 很小的地理区域。 较低层的 ISP 与较高层的 ISP 相连，较高层 ISP 彼此互联。 用户和内容 提供商是较低层 ISP 的客户，较低层 ISP 是较高层 ISP 的客户 。

![image-20210711105355719](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210711105355719.png)

位于相同等级结构层次的邻近一对 ISP 能够对等( p~~r) ，这就是说，能够直接将它 们的网络连到一起，使它们之间的所有流量经直接连接而不是通过上游的中间 TSP 传输、 当两个 ISP 对等时，通常不进行结算

第三方公司创建一个因特网交换点 (InLemet Exchange Point），(通常在一个有自己的交换机的独立建筑物中) , IXP 是一个汇合点，多个 lSP 能够在这里共同对等。

## 分组交换网中的时延，丢包和吞吐量

分组从一台主机(源)出发，通过一系列路由器传输，在另一台主机 (目的地)中结束它的历程。 当分组从一个结点(主机或路游器)沿着这条路径到后继结 点(主机或路由器) .该分组在沿途的每个结点经受了几种不同类型的时延。 这些时延最为重要的是结点处理时延 (nodal processing delay) 、排队时延( queuing delay) 、传输时延 (位ansmission delay) 和传播时延 (propagalÍon delay) ，这些时延总体累加起来是结点总时延( Total nodal delay) 。 

吞吐量：每秒能够传送的数据

![image-20210711110253529](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210711110253529.png)

作为源和目的地之间的端到端路径的一 部分.一个分组从上游结点通过路由器 A 向路由器 B 发送。 我们的目标是在路rl3器 A 刻 画出结点时延。 值得注意的是，路由器 A 具有通往路由器 B 的出链路。 该链路前面有一个 队列(也称为缓存) 。 当该分组从上游结点到达路由器 A 时，路由器 A 检查该分组的首部 以决定该分组的适当出链路，并将该分组导向该链路。 在这个例子中，对该分组的出链路 是通向路由器 B 的那条链路。 仅当在该链路没有其他分组正在传输并且没有其他分组排在 该队列前面时，才能在这条链路上传输该分组;如果该链路当前正繁忙或有其他分组已经 在该链路上排队，则新到达的分组则将参与排队。

- 处理时延：检查分组首部和决定将该分组导向何处所需要的时间是处理时延的一部分。 
- 排队时延：在队列中，当分组在链路上等待传输时，它经受排队时延
- 传输时延：假定分组以先到先服务方式传输，这在分组交换网中是常见的方式，仅当所有已经到 达的分组被传输后，才能传输刚到达的分组。用 L 比特表示该分组的长度，用 R bps (即 b/s) 表示从路由器 A 到路由器 B 的链路传输速率。 例如，对于一条 10Mbps 的以太网链 路，速率 R = 10Mbps; 对于 100Mbps 的以太网链路，速率 R = 100Mbpso 传输时延是 UR。 这是将所有分组的比特推(传输)向链路所需要的时间。
- 传播时延：一旦一个比特被推向链路，该比特需要向路由器 B 传播。 从该链路的起点到路由器 B 传播所需要的时间是传播时延。 该比特以该链路的传播速率传播

传输时延是路由器将分组推出所需要的时间，它是分组长度和链路传输速率的 函数，而与两台路由器之间的距离无关。 另一方面，传播时延是一个比特从一台路由器向 另一台路由器传播所需要的时间，它是两台路由器之间距离的函数，而与分组长度或链路 传输速率无关。 

```
dnodal = dproc + dqueue + dtrans + dprop
```

**丢包（Packet Loss）**

在上述讨论中，我们已经假设队列能够容纳无穷多的分组。 在现实巾，一条链路前的 队列只有有限的容量，尽管排队容量'极大地依赖于路由器设计'和戚本。 因为该排队容量是 有限的，随着流量强度接近 1 ，排队时延并不实际趋向无穷大。 相反，到达的分组将发现 一个满的队列。 由于没有地方存储这个分组，路由器将丢弃( drop) 该分组，即该分组将 会丢失 (lost) 。丢失的分组可能基于端到端的原则重传，以确保所有的数据最终从漉传送到 了目的地。

## 协议层次

![image-20210711115018478](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210711115018478.png)

- 应用层：应用层是网络应用程序及它们的应用层协 议存留的地方。 应用层协议分布在多个端系统上，一个端系统中的应用程序使用协议与另一个端系统 中的应用程序交换信息的分组。 我们把这种位于应用层的信息分组称为报文 (mess鸣叫 。 
- 运输层：因特网的运输层在应用程序端点之间传送应用层报文。 在因特网中，有两个运输协 议，即 TCP 和 UDP
  - TCP 向它的应用程序提供了 面向连接的服务。 这种服务包括了应用层报文向目的地的确保传递和流量控制(即发送方 /接收方速率匹配) 0 TCP 也将长报文划分为短报文，并提供拥塞控制机制，因此当网络拥 塞时，源抑制其传输速率。
  -  UDP 协议向它的应用程序提供无连接服务。 这是一种不提供不 必要服务的服务，没有可靠性，没有流量控制，也没有拥塞控制。 在本书中，我们把运输 层分组称为报文段( segment) 。 
- 网络层：因特网的网络层负责将称为数据报( datagram) 的网络层分组从一台主机移动到另一 台主机。 在一台源主机中的因特网运输层协议 (TCP 或 UDP) 向网络层递交运输层报文段 和目的地址。因特网的网络层包括著名的 IP协议，该协议定义了在数据报巾的各个字段以及端系 统和路由器如何作用于这些字段。 仅有一个 IP 协议，所有具有网络层的因特网组件必须运行 IP 协议。 因特网的网络层也包括决定路由的路由选择协议，它使得数据报根据该路 由从源传输到目的地。 
- 链路层：因特网的网络层通过源和日的地之间的一系列路由器路由数据报。 为了将分组从一个 结点(主机或路由器)移动到路径上的下一个结点，网络层必须依靠眩链路层的服务。 特 别是在每个结点，网络层将数据报下传给链路层，链路层沿着路径将数据报传递给下一个 结点。 在下个结点，链路层将数据报上传给网络层。
- 虽然链路层的任务是将整个帧从一个网络元素移动到邻近的网络元素，而物理层的任 务是将该帧中的一个一个比特从一个结点移动到下一个结点 

## 封装

![image-20210711120125629](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210711120125629.png)

数据从发送端系统的协议枝向下，向上和向下经 过中间的链路层交换机和路由器的协议拢，进而向上到达接收端系统的协议枝。 如我们将 在本书后面讨论的那样，路由器和链路层交换机都是分组交换机。 与端系统类似，路由器 和链路层交换机以多层次的方式组织它们的网络硬件和软件。 而路由器和链路层交换机并 不实现协议楼中的所有层次。 如图 1-24 所示，链路层交换机实现了第一层和第二层;路 由器实现了第一层到第三层。 例如，这意味着因特网路由器能够实现 IP 协议(一种第= 层协议) ，而链路层交换机则不能。 我们将在后面看到，尽管链路层交换机不能识别 IP 地 址，但它们能够识别第二层地址，如以太网地址。 值得注意的是，主机实现了所有 5 个层 次，这与因特网体系结构将它的复杂性放在网络边缘的观点是一致的。



封装( encapsulation ) 。 在发送主机端，一个应用层 报文 (application-layer message) (图 1-24 中的 M) 被传送给运输层。 在最简单的情况下， 运输层收取到报文并附上附加信息(所谓运输层首部信息，图 1-24 中的 H.) ，该首部将被 接收端的运输层使用。 应用层报文和运输层首部信息一道构成了运输层报文段( lransportlayer segment) 。 运输层报文段因此封装了应用层报文。 附加的信息也许包括了下列信息: 如允许接收端运输层向上向适当的应用程序交付报文的信息;如差错检测位信息，该信息 让接收方能够判断报文中的比特是存在途中已被改变。运输层则向网络层传递该报文段， 网络层增加了如源和目的端系统地址等网络层首部信息(图 1-24 中的 Hn) ，产生了网络 层数据报( network-layer datagram) 。 该数据报接下来被传递给链路层，链路层(向然而然地)增加它自己的链路层首部信息并创建链路层帧 (link-layer frame) 。 所以，我们看到在每一层，一个分组具有两种类型的字段:首部宇段和有效载荷字段 (payload field) 。 有效 载荷通常是来自上一层的分组。

# 应用层

![image-20210711155922930](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210711155922930.png)

## 进程通信

### 进程与计算机网络之间的接口

多数应用程序是由通信进程对组成，每对中的两个进程五相发送报文。 从 一个进程向另一个进程发送的报文必须通过下面的网络。 进程通过一个称为套接字 (socket) 的软件接口向网络发送报文和从网络接收报文。

![image-20210711213039754](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210711213039754.png)

如该图所示，**套接字是同一台主机内应用 层与运输层之间的接口**。由于该套接字是建立网络应用程序的可编程接口，因此套接字也 称为应用程序和网络之间的应用程序编程接口 (Application Programming Interface , API) 。

 应用程序开发者可以控制套接字在应用层端的一切，但是对该套接字的运输层端几乎没有 控制权。 应用程序开发者对于运输层的控制仅限于:

- 选择运输层协议;
- 也许能设定几 个运输层参数，如最大缓存和最大报文段长度等。

一旦应用程序开 发者选择了一个运输层协议(如果可供选择的话) ，则应用程序就建立在由该协议提供的 运输层服务之上。

### 进程寻址

在一台主机上运行 的进程为了向在另一台主机上运行的进程发送分组，接收进程需要有一个地址。 为了标识该 接收进程，需要定义两种信息:、

- 主机的地址;
- 定义在目的主机中的接收进程的标识符。

在因特网中，主机由其 IP 地址( IP address) 标识。 此时，我们只要知道 IP 地址是一个 32 比特的量且它能够唯一地标识该主机就 够了。

 除了知道报文送往目的地的主机地址外，发送进程还必须指定运行在接收主机上的 接收进程(更具体地说，接收套接字) 。 因为一般而言一台主机能够运行许多网络应用， 这些信息是需要的。 目的地端口号(port number) 用于这个目的。 已经给流行的应用分配 了特定的端口号。 例如. Web 服务器用端口号 80 来标识。

## 可供应用程序使用的运输

- 可靠数据传输：以确保由应用程序的一端发送的数据正确、完全地交付给该应用程序的另一端。 如果一个协议提供了这样的确保数据交付服务，就认为提供了可靠数据传输( reliable data transfer) 。 
- 吞吐量：运输层协议能够以某种特定的速率提供确 保的可用吞吐量。 使用这种服务，该应用程序能够请求 r 比特/秒的确保吞吐量，并且该 运输协议能够确保可用吞吐量-总是为至少 r 比特/秒。 具有吞吐量要求的应用程序被称为 带宽敏感的应用 (bandwidth- sensitive applicaLion) 。
- 定时：运输层协议也能提供定时保证。如同具有吞吐量保证那样，定时保证能够以多种形 式实现。 一个保证的例子如 :发送方注人进套接字中的每个比特到达接收方的套接字不 迟于 100ms。
- 安全性

### 因特网提供的运输服务

**TCP服务**

- 面向连接的服务：在应用层数据报文开始流动之前， TCP 让客户和服务器互相交 换运输层控制信息。 这个所谓的握手过程提示客户和服务器，使它们为大量分组 的到来做好准备。 在握手阶段后，一个 TCP 连接 (TCP connection) 就在两个进 程的套接字之间建立了。 这条连接是全双工的，即连接双方的进程可以在此连接 上同时进行报文收发。当应用程序结束报文发送时，必须拆除该连接。 
- 可靠的数据传输服务：通信进程能够依靠 TCP，无差错、按适当顺序交付所有发 送的数据。 当应用程序的一端将字节流传进套接字时，它能够依靠 TCP 将相同的 字节流交付给接收方的套接字，而没有字节的丢失和冗余。 

**SSL**

因特网界已经研制了 TCP 的加强版 . 本，称为安全套接字层 (Secure Sockets Layer, SSL) 。 用 SSL 加强后的 TCP 不仅能够做 『 传统的 TCP 所能做的一切，而且提供了关键的进程到进程的安全性服务，包括加密、数 据完整性和端点鉴别 。

 我们强调 SSL 不是与 TCP 和 UDP 在相同层次上的第三种因特网 运输协议，而是一种对TCP 的加强，这种强化是在应用层上实现的。 特别是，如果一个 | 应用程序要使用 SSL 的服务，它需要在该应用程序的客户端和服务器端包括 SSL 代码 (利用现有的、高度优化的库和类 ) 0 SSL 有它自己的套接字 API，这类似于传统的 TCP 套接字 API。 当一个应用使用 SSL 时，发送进程向 SSL 套接字传递明文数据;在发送主 机中的 SSL 则加密该数据并将加密的数据传递给 TCP 套接字。 加密的数据经因特网传送 到接收进程中的 TCP 套接字。 该接收套接字将加密数据传递给 SSL，由其进行解密。 最 后， SSL 通过它的 SSL 套接字将明文数据传递给接收进程。

**UDP**

- UDP 是一种不提供不必要服务的轻量级运输协议，它仅提供最小服务。 UDP 是无连 接的，因此在两个进程通信前没有握手过程。 UDP 协议提供一种不可靠数据传送服务，也 就是说，当进程将一个报文发送进 UDP 套接字时， UDP 协议并不保证该报文将到达接收 进程。 不仅如此，到达接收进程的报文也可能是乱序到达的。 
- UDP 没有包括拥塞控制机制，所以 UDP 的发送端可以用它选定的任何速率向其下层 (网络层)注人数据。 (然而，值得注意的是实际端到端吞吐量可能小于这种速率，这可 能是因为中间链路的带宽受限或因为拥塞而造成的。) 

## 应用层协议

应用层协议 (application-layer protocol) 定义了运行在不同 端系统上的应用程序进程如何相互传递报文。 特别是应用层协议定义了: 

- 交换的报文类型，例如请求报文和响应报文
- 各种报文类型的语法，如报文中的各个字段及这些字段是如何描述的。 
- 字段的语义，即这些字段中包含的信息的含义。
-  一个进程何时以及如何发送报文，对报文进行响应的规则。



Web 页面 (Web page) (也叫文档)是由对象组成的。 多数 Web 页面含有一个 HTML 基本文件( base HTML file) 以及几个引用对象。 例如，如果一个 Web 页面包含 HTML 文本和 5 个 JPEG 图 形，那么这个 Web 页面有 6 个对象:一个 HTML基本文件加 5 个图形。

 HTML 基本文件通 过对象的 URL 地址引用页面中的其他对象。 每个 URL 地址由两部分组成 :存放对象的**服务器主机名**和对象的**路径名** 。 例如， URL 地址 http://wrww.someScbool.edu/someDepartment/picture.gif，其中的 www. someSchool. edu 就是主机名，/someDepartment/picture.gif就 是路径名 。

![image-20210712211952732](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210712211952732.png)

HTTP 使用 TCP 作为它的支撑运输协议 (而不是在 UDP 上运行) ,  客户首先发起 一个与服务器的 TCP 连接。 一旦连接建立，该浏览器和服务器进程就可以通过套接字接口访问 TCP。 

 HTTP 是一个无状态协议 (stateless protocol) : 服务器向客户发送被请求的文件，而不存储任何关于该客户 的状态信息。 假如某个特定的客户在短短的几秒钟内两次请求同一个对象，服务器并不会 因为刚刚为该客户提供了该对象就不再做出反应，而是重新发送该对象

### 采用非持续连接的HTTP

在非持续连接情况下，从服务器向客户传送一个 Web 页面的步骤。 假设该 页面含有一个 HTML 基本文件和 10 个 JPEG 图形，并且这 11 个对象位于同一台服务器上。 假设base HTML file的URL地址是http://www.someSchool.edu/someDepartment/home.index

1. HTTP 客户进程在端口号 80 发起一个到服务器 www.someSchool.edu 的 TCP 连接， 该端口号是 HTTP 的默认端口。在客户和服务器上分别有一个套接字与该连接相关联。
2.  HTTP 客户经它的套接字向该服务器发送一个 HTTP 请求报文。 请求报文中包含了 路径名 /someDepartment/home.index. 
3. HTTP 服务器进程经它的套接字接收该请求报文，从其存储器 (RAM 或磁盘)中 检索出对象 www. someSchool.edνsomeDepartment/home.index，在一个 HTTP 响应报文中封装对象，并通过其套接字向客户发送响应报文。 
4. HTTP 服务器进程通知 TCP 断开该 TCP 连接。 (但是直到 TCP 确认客户已经完整地 收到响应报文为止，它才会实际中断连接。)
5. HTTP 客户接收响应报文， TCP 连接关闭。 该报文指出封装的对象是一个 HTML 文 件，客户从响应报文中提取出该文件，检查该 HTML 文件，得到对 10 个 JPEG 图 形的引用。 
6. 对每个引用的 JPEG 图形对象重复前 4 个步骤。 

上面的步骤举例说明了非持续连接的使用，其中每个 TCP 连接在服务器发送一个对象后 关闭， ~Il该连接并不为其他的对象而持续下来。 值得注意的是每个 TCP 连接只传输一个请求 报文和一个响应报文。 因此在本例中，当用户请求该 Web 页面时，要产生 11 个 TCP 连接。 

![image-20210712214249596](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210712214249596.png)

**往返时间（Round-Trip Time， RTT）**：该 时间是指一个短分组从客户到服务器然后再返回客户所花费的时间 。 RTT 包括分组传播时延、分组在中间路由器和交换机上的排队时延以及分组处理时延。

现在考虑当用户点击超链接时会发生什么现象。

 如图 2-7 所示，这引起浏览器在它 和 Web 服务器之间发起一个 TCP 连接;

这涉及一次" 三次握手"过程，即]客户向服务器 发送一个小 TCP 报文段，服务器用一个小 TCP 报文段做出确认和响应，最后，客户向服 务器返回确认。三次握手中前两个部分所耗费的时间占用了一个 RTT。完成了三次握手的 前两个部分后，客户结合三次握手的第三部分(确认)向该 TCP 连接发送一个 HTTP 请求 报文。一旦该请求报文到达服务器，服务器就在该 TCP 连接上发送 HTML 文件。 该 HTTP 请求/响应用去了另一个 RTT。 因此，粗略地讲，总的响应时间就是两个 RTT 加上服务器传输 HTML 文件的时间。

### 采用持续连接的HTTP

非持续连接有一些缺点。 

- 首先，必须为每一个请求的对象建立和维护一个全新的连接。 对于每个这样的连接，在客户和服务器巾都要分配 TCP 的缓冲区和保持 TCP 变量。
- 第二 ，就像我们刚描述的那样，每一个对象经受两倍 RTT 的交付时延， 即一个 RTT 用于创建 TCP，另一个 RTT 用于请求和接收一个对象。 

### HTTP报文格式

HTTP 规范包含了对 HTTP 报文格式的定义。 HTTP 报文有 两种

- 请求报文
- 响应报文。 

**HTTP请求报文**

```
GET /somedir/page.html HTTP/1.1 
Host: www.someschool.edu
Connection: close
User-agent: Mozilla/5.0 
Accept-language: fr

```

HTTP 请求报文的第一行 叫做请求行 (request line) ，其后继的行叫做首部行( header line) 。 请求行有 3 个字段:

- 方法字段
- URL 字段
- HTTP 版本字段。 

首部行的解释

- 首部行 Host: www. someschool. edu 指明了对象所在的 主机。你也许认为该首部行是不必要的，因为在该主机中已经有一条 TCP 连接存在了 。 但是，如我们将在 2.2.5 节中所见，该首部行提供的信息是 Web 代理高速缓存所要求的 。
- 通过包含 ConnecLion: close 首部行，该浏览器告诉服务器不希望麻烦地使用持续连 接，它要求服务器在发送完被请求的对象后就关闭这条连接。
- User-agent: 首部行用来 指明用户代理，即向服务器发送请求的浏览器的类型。 这个首部行是有用的，因为服务器可以有效地为不同类型的用户代理实际发送相同对象的不同版本。 (每个版本都由相同的URL寻址。 )
- 最后， Accept-language : 首部行表示用户想得到该对象的法语版本(如果服务器中有这样的对象的话) ; 否则，服务器应当发送它的默认版本。 Accept-language : 首部行仅是 HTTP 中可用的众 多内容协商首部之一。

![image-20210713160306068](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210713160306068.png)

"实体体" (entity body) ： 使用 GET 方法时实体体为空，而使用 POST 方法时才使用该实体体。 当用户提交表单时， HTTP 客户常常使用 POST 方法。

但是用GET方法同样能够生成表单请求报文： HTML 表单经常使用 GET 方法，并在(表单字段中)所请求的 U且中包括输入的 数据。 例如，一个表单使用 GET 方法，它有两个字段，分别填写的是" monkeys" 和 "bananas"，这样，该 URL 结构为 www.somesite.com/animalsearch?monkeys&bananas。 在 日复一日的网上冲浪中，你也许已经留意到了这种扩展的URL。 

HEAD 方法类似于 GET 方法。 当服务器收到使用 HEAD 方法的请求时，将会用一个 HTTP 报文进行响应，但是并不返回请求对象。 应用程序开发者常用 HEAD 方法进行调试 跟踪。 PUT 方法常与 Web 发行工具联合使用，它允许用户上传对象到指定的 Web 服务器 上指定的路径(目录) 。PUT 方法也被那些需要向 Weh 服务器上传对象的应用程序使用。 DELETE 方法允许用户或者应用程序删除 Web 服务器上的对象。 

**HTTP响应报文**

```
HTTP/1.1 200 OK
Connection: close
Date: Tue, 09 Aug 2011 15:44:04 GMT
Server: Apache/2.2.3 (CentOS)
Last-Modified: Tue, 09 Aug 2011 15:11:03 GMT
Content-Length: 6821
Content-Type: text/html

(data data data data data ...)
```

HTTP响应报文它有三个部分

-  一个初始状态行 (status line) 
- 6 个 首部行 (header line) 
- 实体体 (entity body) 。 

状态行有 3 个字段

- 协议版本 宇段
- 状态码
- 相应状态信息。 

在这个例子中，状态行指示服务器正在使用 HTTP/l. 1, 并且一切正常(即服务器已经找到并正在发送所请求的对象) 。 

首部行解读：

- Date: 首部行指示服务器产生并发送该响应报文的日期和时间。 值得 一提的是，这个时间不是指对象创建或者最后修改的时间;而是服务器从它的文件系统中 检索到该对象，插入到响应报文，并发送该响应报文的时间。
-  Lasl-M创ified: 首部行 对既可能在本地客户也可能在网络缓存服务器上的对象缓存来说非常重要。 我们将很快详 细地讨论缓存服务器(也叫代理服务器) 0 
-  Conlent-Type: 首部行指示了实体体中的对象是 HTML 文本" 

![image-20210713161929134](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210713161929134.png)

状态码和它们对应的短语。 状 态码及其相应的短语指示了请求的结果。 一些常见的状态码和相关的短语包括: 

- 200 OK: 请求成功 信息在返回的响应报文中。 
-  301 Moved Permanently: 请求的对象已经被永久转移了，新的 URL 定义在响应报 文的LocaLioD: 首部行中。 客户软件将自动获取新的 URL。 
- 400 Bad Request: 一个通用差错代码，指示该请求不能被服务器理解。
- 404 Not Found: 被请求的文档不在服务器上
-  505 HTTP Version Not Supported: 服务器不支持请求报文使用的 HTTP 协议版本。 

### Cookie

![image-20210713165859642](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210713165859642.png)

 cookie 技术有 4 个组件:

- 在 HTTP 响应报文中的一个 cookie 首部行

- 在 HTTP 请求报文中的一个 cookie 首部行

- 在用户端系统中保留有一个 cookie 文件，并由用户的浏览器进行管理

- 位于 Web 站点的一个后端数据库。

  

ookie 可以用于标识一个用户 。 用户首次访问一个站点时， 可能需要提供一个用户标识(可能是名字) 。 在后继会话中，浏览器向服务器传递一个 cookie 首部，从而向该服务器标识了用户 。 因此 cookie 可以在无状态的 HTTP 之上建立一 个用户会话层。

### Web缓存

Web 缓存器 (Web cache) 也叫代 理服务器 (proxy server) ，它是能够代表 初始 Web 服务器来满足 HTTP 请求的网 络实体。 Web 缓存器有自己的磁盘存储 空间，并在存储空间中保存最近请求过 的对象的副本。 

![image-20210713172615387](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210713172615387.png)

一旦某浏览 器被配置，每个对某对象的浏览器请求 首先被定向到该 Web 缓存器。 举例来 说，假设浏览器正在请求对象  http://www.someschool.edu/campus.gif
将会发生如下情况:

- 浏览器建立一个到 Web 缓存器的 TCP 连接，并向 Web 缓存器中的对象发送一个 HTTP 请求。 
- Web 缓存器进行检查，看看本地是否存储了该对象副本。 如果有， Web 缓存器就 向客户浏览器用 HTTP 响应报文返回该对象。
- 如果 Web 缓存器中没有该对象，它就打开一个与该对象的初始服务器(如 www. someschool. edu) 的 TCP 连接。 Web 缓存器则在这个缓存器到服务器的 TCP 连接上发送一个对该对象的 HTTP 请求。 在收到该请求后，初始服务器向该 Web 缓存器发送具有该对象的 HTTP响应。 
- 当 Web 缓存器接收到该对象时，它在本地存储空间存储一份副本，并向客户的浏 览器用盯TP 响应报文发送该副本(通过现有的客户浏览器和 Web 缓存器之间的 TCP 连接) 。 

值得注意的是 Web 缓存器是服务器同时又是客户 。 当它接收浏览器的请求并发回响 应时，它是一个服务器。 当它向初始服务器发出请求并接收响应时，它是一个客户 。 

### 条件GET

尽管高速缓存能减少用户感受到的响应时间，但也引人了一个新的问题，即存 放在缓存器中的对象副本可能是陈旧的。

条件 GET (conditional GET) 方法

- 请求报文使用 GET 方法;
- 请求报文中包 含一个"If-Modified -Since : "首部行

用一个例子解释条件GET的工作流程

1. 首先，一个代理缓存器( proxy cache) 代表一个请求浏览器，向某 Web 服务器发送一个请求报文:

   ```
   GET /fruit/kiwi.gif HTTP/1.1 
   Host: www.exotiquecuisine.com
   ```

2. 其次，该 Web 服务器向缓存器发送具有被请求的对象的响应报文: 

   ```
   HTTP/1.1 200 OK 
   Date: Sat, 8 Oct 2011 15:39:29 
   Server: Apache/1.3.0 (Unix)
   Last-Modified: Wed, 7 Sep 2011 09:23:24
   Content-Type: image/gif
   
   (data data data data data ...)
   ```

   该缓存器在将对象转发到请求的浏览器的同时，也在本地缓存了该对象。 重要的是， 缓存器在存储该对象时也存储了最后修改日期。 

3. 一个星期后，另一个用户经过该缓 存器请求同一个对象，该对象仍在这个缓存器中。 由于在过去的一个星期中位于 Web 服 务器上的该对象可能已经被修改了，该缓存器通过发送一个条件 GET 执行最新检查。 具 体说来，该缓存器发送: 

   ```
   GET /fruit/kiwi.gif HTTP/1.1
   Host: www.exotiquecuisine.com 
   If-modified-since: Wed, 7 Sep 2011 09:23:24
   
   ```

   值得注意的是 H-Modifjed-Since: 首部行的值正好等于一星期前服务器发送的响应报文 中的La.st- Modified :首部行的值。 该条件 GET 报文告诉服务器，仅当自指定日期之后该对 象被修改过，才发送该对象。

4. 假设该对象自 2011 年 9 月 7 日 09: 23: 24 后没有被修改。 接下来的第四步， Web 服务器向该缓存器发送一个响应报文: 

   ```
   HTTP/1.1 304 Not Modified 
   Date: Sat, 15 Oct 2011 15:39:29 
   Server: Apache/1.3.0 (Unix)
   
   (empty entity body)
   
   ```

   

## DNS：因特网的目录服务

识别主机有两种方式：

- 主机名：www.baidu.com
- IP 地址： 121.7.106.83

域名系统 (Domain Name System , DNS) 的主要任务：进行主机名到 E 地址转换的目录服务

- 一个由分层的 DNS 服务器( DN server) 实现的分布式数据库
- 一个使得主机能够查询分布式数据库的应用层协议。

 DNS 服务器通常是运行 BIND (Berkeley Internet Name Domain) 软件[ BIND 2012 J 的 UNJX 机器。 DNS 协议运行在 UDP 之上，使用 53 号端口 。

### DNS的工作机制

![image-20210713210706722](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210713210706722.png)

为了处理扩展性问题， DNS 使用了大量的 DNS 服务器，它们以层次方式组织，并且 分布在全世界范围内 。 没有一台 DNS 服务器拥有因特网上所有主机的映射。相反，该映 射分布在所有的 DNS 服务器上。

 大致说来，有 3 种类型的 DNS 服务器:

- 根 DNS 服务器
-  顶级域 (Top-Level Domain , TLD) DNS 服务器
- 权威 DNS 服务器。 

假定一个 DNS 客户要决定主机名 www.amazon.com的地址：先与根服务器之一联系，它将返回顶级域名 com 的 TLD 服务器的IP地址。 该客户则与这 些TLD服务器之一联系，它将为 amazoo. com 返回权威服务器的 IP 地址。 最后，该客户与amazon.com权威服务器之一联系，它为主机名www.amazon.com 返回其IP地址。

根、TLD和权威 DNS 服务器都处在该 DNS 服务器的层次结构中，如图 2-19 中所示。 还有另一类重要的 DNS ，称为本地 DNS 服务器 (local DNS server) 。 一个本地 DNS 服务器 严格说来并不属于该服务器的层次结构，但它对 DNS 层次结构是重要的。

当主机与某个 ISP 连接时，该 ISP 提供一台主机的 E 地址，该主机具有一台或多台其本地 DNS 服务器的 IP地址。 当主机发出 DNS 请求时，该请求被发往本地 DNS 服务器，它起着代理的作用， 并将该请求转发到 DNS 服务器层次结构中。

![image-20210714162138304](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210714162138304.png)

**DNS缓存**： DNS 缓存的原 理非常简单。 在一个请求链中，当某 DNS 服务器接收一个 DNS 回答(例如，包含主 机名到 IP 地址的映射)时，它能将该回答 中的信息缓存在本地存储器中。 



 ### DNS记录和报文

共同实现 DNS 分布式数据库的所有 DNS 服务器存储了资源记录 (Resource Record , RR) , RR 提供了主机名到 E 地址的映射。 每个 DNS 回答报文包含了一条或多条资源记录。

资源记录是一个包含了下列字段的 4 元组:

```
(Name, Value, Type, TTL)
```

TTL 是该记录的生存时间，它决定了资源记录应当从缓存中删除的时间。 

## 套接字编程

### UDP

UDP 套接字的两个通信进程之间的交互。 在发送进程能够将 数据分组推出套接字之门之前，当使用 UDP 时，必须先将目的地址附在该分组之上。 在 该分组传过发送方的套接字之后.因特网将使用该目的地址通过因特网为该分组选路到接 收进程的套接字。 主与分组到达接收套接字时，接收进程将通过该套接宇取回分组，进而检 查分组的内容并采取适当的动作。 

分组目标地址上包含：

- 目的地的IP地址
- 端口号 (port number) 的标识符：因为一台主机可能运行许多网络应用进 程，每个进程具有一个或多个套接字，所以在目的主机指定特定的套接字也是必要的。
- 发送方的源地址和源套接字的端口号

归纳起来，发送进程为分组附上的目 的地址是由目的主机的IP地址和目的地套接字的端口号组成的。 此外，如我们很快将看到的那样，发送方的源地址也是由源主机的IP地址和源套接字的端口号组成，该源地址也要附在分组之上。 然而，将源地址附在分组之上通常并不是由 UDP 应用程序代码所为， 而是由底层操作系统自动完成的。 

![image-20210714181443153](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210714181443153.png)

```python
UDPClient.py

from socket import *
serverName = ‘hostname’ 
serverPort = 12000 
clientSocket = socket(socket.AF_INET, socket.SOCK_DGRAM) 
message = raw_input(’Input lowercase sentence:’) 
clientSocket.sendto(message,(serverName, serverPort))
modifiedMessage, serverAddress = clientSocket.recvfrom(2048)
print modifiedMessage 
clientSocket.close()

UDPServer.py

from socket import * 
serverPort = 12000 
serverSocket = socket(AF_INET, SOCK_DGRAM) 
serverSocket.bind((’’, serverPort)) 
print ”The server is ready to receive” 
while 1: 
    message, clientAddress = serverSocket.recvfrom(2048) 
    modifiedMessage = message.upper() 
    serverSocket.sendto(modifiedMessage, clientAddress)

```



### TCP

![image-20210714182752650](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210714182752650.png)

- 随着服务器进程的运行，客户进程能够向服务器发起一个 TCP 连接。 这是由客户程序 通过创建一个 TCP 套接字完成的。 当该客户生成其 TCP 套接字时，它指定了服务器中的 欢迎套接字的地址，即服务器主机的 IP 地址及其套接字的端口号。 
- 生成其套接字后，该 客户发起了一个三次握手并创建与服务器的一个 TCP 连接。 发生在运输层的三次握手，对 于客户和服务器程序是完全透明的。 
- 在三次握手期间，客户进程敲服务器进程的欢迎之门。 当该服务器"听"到敲门时， 它将生成一扇新门(更精确地讲是一个新套接字) 

![image-20210714183157239](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210714183157239.png)

```python
TCPClient.py

from socket import * 
serverName = ’servername’ 
serverPort = 12000
clientSocket = socket(AF_INET, SOCK_STREAM) 
clientSocket.connect((serverName,serverPort)) 
sentence = raw_input(‘Input lowercase sentence:’)
clientSocket.send(sentence) 
modifiedSentence = clientSocket.recv(1024)
print ‘From Server:’, modifiedSentence 
clientSocket.close()

clientSocket.connect((serverName,serverPort)) 
前面讲过在客户能够使用一个 TCP 套接字向服务器发送数据之前(反之亦然) ，必须 在客户与服务器之间创建一个 TCP 连接。 上面这行就发起了客户和服务器之间的这条 TCP 连接。 connect()方法的参数是这条连接中服务器端的地址。 这行代码执行完后，执行三次握手，并在客户和服务器之间创建起一条 TCP 连接。

clientSocket.send(sentence) 
值得注意的是，该 程序并未显式地创建一个分组并为该分组附上目的地址，而使用 UDP 套接字却要那样做。 相反，客户程序只是将字符串sentence中的字节放入该TCP 连接中去。 客户然后就等待接收来自服务器的字节。 

TCPServer.py

from socket import * 
serverPort = 12000
serverSocket = socket(AF_INET,SOCK_STREAM) 
serverSocket.bind((‘’,serverPort)) 
serverSocket.listen(1) 
print ‘The server is ready to receive’ 
while 1: 
  connectionSocket, addr = serverSocket.accept() 
  sentence = connectionSocket.recv(1024) 
  capitalizedSentence = sentence.upper() 
  connectionSocket.send(capitalizedSentence) 
  connectionSocket.close()
  
  
serverSocket.listen(l) 
该行让服务器聆听来自客户的 TCP 连接请求。 其中参数定义了请求连接的最大数 (至少为 1 ) 。 

connectionSocket, addr = serve.rSocket.accept() 
当客户敲该门时，程序为 serverSocket 调用 accept() ，这在服务器中创建了一个称为 connectionSocket 的新套接字，由这个特定的客户专用。 客户和服务器则完成了握手，在客户的clientSocket和服务器的serverSocket之间创建了一个 TCP 连接。 借助于创建的 TCP 连接，客户与服务器现在能够通过该连接相互发送字节。 使用 TCP. 从一侧发送的所有字节 不仅确保到达另一侧，而且确保按序到达。 
```

# 运输层

运输层协议为运行在不同主机中的应用进程之间提供了逻辑通信 (logic communication) 功能。 从应用程序的角度看，通过逻辑通信，运行不同进程的主机好像直接相连一样。

 在发送端，运输 层将从发送应用程序进程接收到的报文转换成运输层分组，称为 运输层报文段 ( segment) 。 实现的方法(可能)是将应用报文划分为较小的块，并为每块加上一个运输层首部以生成运输层报文段。 然后，在发送端系统中，运输层将这些报文段传递给网络层，网路层将其封装成网络层分组(即数据报)并向目的地发送。 

 注意到下列 事实是重要的:网络路由器仅作用于该数据报的网络层字段;即它们不检查封装在该数据 报的运输层报文段的字段。 在接收端，网络层从数据报中提取运输层报文段，并将该报文 段向上交给运输层。 运输层则处理接收到的报文段，使该报文段中的数据为接收应用进程 使用。 

![image-20210714224610057](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210714224610057.png)



运输层和网络层的关系

-  网络层提供了主机之间的逻辑 通信
- 运输层为运行在不同主机上的进程之间提供了逻辑通信。

UDP 和 TCP 最基本的责任是，将两个端系统间 E 的交付服务扩展为运行在端系统上的两 个进程之间的交付服务。 将主机间交付扩展到进程间交付被称为运输层的多路复用 ( transport -layer multiplexing) 与多路分解( demultiplexing) 

UDP 和 TCP 还可以通过在其报文段首部中包括差错检查字段而提 供完整性检查。 进程到进程的数据交付和差错检查是两种最低限度的运输层服务，也是 UDP 所能提供的仅有的两种服务。 特别是，与 IP 一样， UDP 也是一种不可靠的服务，即 不能保证一个进程所发送的数据能够完整无缺地(或全部! )到达目的进程。

TCP 为应用程序提供了几种附加服务。 

- 它提供可靠数据传输( reliable dala tTansfer) 。 通过使用流量控制、序号、确认和定时器(本章将详细介绍这些技术)， TCP 确保正确地、按序地将数据从发送进程交付给接收进程。 
-  TCP 还提供拥塞控制( congestion conlrol) 

## 多路复用和多路分解

运输层的多路复用与多路分解，也就是将由网络层提供的主机到 主机交付服务延伸到为运行在主机上的应用程序提供进程到进程的交付服务

![image-20210714231051243](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210714231051243.png)

一个进程(作为网络应用的一部分)有一个或多个套接字 (socket) ，它相当于从网络向进程传递数据和从进程向网络传递数据的门户 。 因此，如 图 3-2 所示，在接收主机中的运输层实际上并没有直接将数据交付给进程，而是将数据交 给了一个中间的套接字。 由于在任一时刻，在接收主机上可能有不止一个套接字，所以每 个套接字都有唯一的标识符。 标识符的格式取决于它是 UDP 还是 TCP 套接字

**多路分解 ( demulliplexing)** ：现在我们考虑接收主机怎样将一个到达的运输层报文段定向到适当的套接字。 为此目的，每个运输层报文段中具有几个字段。 在接收端，运输层检查这些字段，标识出接收套 接字，进而将报文段定向到该套接字。 将运输层报文段中的数据交付到正确的套接字的工 作称为多路分解 ( demulliplexing) 。

**多路复用( multiplexing)** ：在源主机从不同套接字中收集数据块，并为每个数据 块封装上首部信息(这将在以后用于分解)从而生成报文段，然后将报文段传递到网络层，所有这些工作称为多路复用( multiplexing) 

![image-20210715112216904](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210715112216904.png)

主机中多路复用和多路分解的实际工作过程，运输层多路复用要求：

- 套接字有唯一标识符
- 每个报文段有特殊字段来指示该报文段所要交付到的套接字：这些特殊字段是源端口号字段 (source port oumber field) 和目的端口号字段 (destination port nurnber field) 

端口号是一个 16 比特的数，其大小在 0-65535 之 间 。 0-1023 也围的端口号称为周知端口号( well-known port number) ，是受限制的，这是指它们保留给诸如 HTTP (它使 用端口号 80) 和FTP(它使用端口号 21)之类的周知应用层 协议来使用。 

### 无连接的多路复用与多路分解

运输层实现分解服务:在主机上的每个套接字能够分配 一个端口号，当报文段到达主机时，运输层检查报文段中的目的端口号，并将其定向到相 应的套接字。 然后报文段中的数据通过套接字进人其所连接的进程。 如我们将看到的那 样， UDP 基本上是这样做的。 然而，TCP 中的多路复用与多路分解更为 复杂。

![image-20210715113545623](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210715113545623.png)

注意到下述事实是重要的:一个 UDP 套接字是由一个二元组来全面标识的，该二元组包含一个目的 IP地址和一个目的端口号。 因此，如果两个 UDP 报文段有不同的源IP地 址和/或源端口号，但具有相同的目的 IP地址和目的端口号，那么这两个报文段将通过相同的目的套接字被定向到相同的目的进程。 

源端口号的用途是什么呢?如图 3-4 所示，在 A 到 B 的报文段 中，源端口号用作"退回地址"的一部分，即当 B 需要回发一个报文段给 A 时， B 到 A 的报文段中的目的端口号便从 A 到 B 的报文段中的源端口号中取值。 (完整的返回地址是 A 的 IP 地址和源端口号。)

### 面向连接的多路复用与多路分解

![image-20210715174119710](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210715174119710.png)

TCP 套 接字和 UDP 套接字之间的一个细微差别是， TCP 套接字是由一个四元组(源 IP 地址，源 端口号，目的 IP 地址，目的端口号)来标识的。

特别与 UDP 不同的是，两个具有不同源 IP 地址或源端口号的到达 TCP 报文段将被定向到两个不同的套接字，除非 TCP 报文段携带了初始创建连接的请求e。因为TCP是面向连接的协议，每一个源都需要有一个自己的连接。

服务器主机可以支持很多并行的 TCP套接字，每个套接字与一个进程相联系，并由其 四元组来标识每个套接字。 当一个 TCP 报文段到达主机时，所有 4 个字段(源 IP地址， 源端口，目的 IP地址，目的端口)被用来将报文段定向(分解)到相应的套接字。

## UDP协议

除了复用/分解功 能及少量的差错检测外，它几乎没有对 IP增加别的东西。 实际上，如果应用程序开发人 员选择 UDP 而不是 TCP ，则该应用程序差不多就是直接与 IP 打交道。 UDP 从应用进程得 到数据，附加上用于多路复用/分解服务的源和目的端口号字段，以及两个其他的小字段， 然后将形成的报文段交给网络层。 网络层将该运输层报文段封装到一个IP 数据报中，然 后尽力而为地尝试将此报文段交付给接收主机。 如果该报文段到达接收主机， UDP 使用目的端口号将报文段中的数据交付给正确的应用进程。 值得注意的是，使用 UDP 时，在发 送报文段之前，发送方和接收方的运输层实体之间没有握手。 正因为如此， UDP 被称为是 无连接的。

### UDP报文段

![image-20210715190333528](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210715190333528.png)

应用层数据占用 UDP 报文段的 数据字段。  UDP 首部只有 4 个字段，每个 字段由两个字节组成。

- 通过端口号可以使目 的主机将应用数据交给运 行在目的端系统中的相应进程(即执行分解功能) 
-  长度字 32比特段指示了在 UDP 报文段中的字节数(首部加数据) ，因为数 据字段的长度在一个 UDP 段中不同于在另一个段中，故需要 一个明确的长度
- 接收方使用检验和来检查在该报文段中是 杏出现了差错

### UDP校验和

发送方的 UDP 对报文段中的所有 16 比特字的和进行反码运算，求和时遇到的任何溢出都被回卷。得到的结果被放在 UDP 报文段中的检验和字段。 

```
举例来说，假定我们有下面 3 个 16 比特的字:

0110011001100000
0101010101010101
1000111100001100

这些 16 比特字的前两个之和是:
0110011001100000 
0101010101010101
----------------
1011101110110101

再将上面的和与第三个字相加，得出:
1011101110110101
1000111100001100
----------------
0100101011000010

注意到最后一次加法有滥出，它要被回卷。反码运算就是将所有的 0 换成 1 ，所有的 1 转换成 0。 因此，该和 0100101011000010 的反码运算结果是 1011010100111101 ，这变为 了检验和。

```

```
你可能想知道为什么 UDP 首先提供了检验和，就像许多链路层协议(包括流行的 以太网协议)也提供了差错检测那样。 其原因是由于不能保证源和目的之间的所有链路都提供差错检测;这就是说，也许这些链路中的一条可能使用没有差错检测的协议。 此外，即使提文段经链路正确地传输，报文段存储在某台路由器的内存中时，也可能引入比特差错。 在既无法确保连链路的可靠性，又无法确保内存中的差错检测的情况下， 如果端到端数据传输服务要提供差错检测. UDP 就必须在端到端基础上在运输层提供差 错检测 。 这是一个在系统设计中被称颂的端到端原则( end -enu principle) 的例子 [ Saltzer 1984] ，该原则表述为因为某种功能(在此时为差错检测)必须基于端到端实 现"与在较高级别提供这些功能的代价相比，在较低级别上设置的功能可能是冗余的或几乎没有价值的。
```

## 可靠传输原理

在本节中，考虑到底层信道模型越来越复杂，我们将不断地开发一个可靠数据传输协议的发送方和接收方。例如，我们将考虑当底层信道能够损坏比特或丢失整个分组时，需 要什么样的协议机制。 

这里贯穿我们讨论始终的一个假设是分组将以它们发送的次序进行 交付，某些分组可能会丢失; 这就是说，底层信道将不会对分组重排序。 

![image-20210715192702984](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210715192702984.png)

图示说 明了用于数据传输协议的接口 。 通过调用 rdt_send()函数，可以调用数据传输协议的发送方。 它将要发送的数据交付给位于接收方的较高层。 (这里 rdl 表示可靠数据传输协议， _seod 指示 rdt 的发送端正在被调用 ) 

在接收端，主与分组从信道的接收端到达时，将调用 rdt_rcv () 。 当rdt协议想要向较高层交付数据时， 将通过调用 deliver_daLa()来完成。

 后面，我们将使用术语"分组"而不用运输 层的"报文段" 。 因为本节研讨的理论适用于一般的计算机网络，而不只是用于因特网运 输层，所以这时采用通用术语"分组"也许更为合适

### 构造可靠的传输协议

###  rdt 2.0版本

在研发一种经这种信道进行可靠通信的协议之前，首先考虑一下人们会怎样处理这类 情形。 考虑一下你自己是怎样通过电话口述一条长消息的。 在通常情况下，报文接收者在 听到、理解并记下每句话后可能会说 "OK" 。 如果报文接收者听到一句含糊不清的话时， 他可能要求你重复刚才那句话。 这种口述报文协议使用了肯定确认 (positive acknowledgment) (" OK" )与否定确认 (negative acknowledgment) ("请重复一遍" ) 。 这些控制报文 使得接收方可以让发送方知道哪些内容被正确接收，哪些内容接收有误并因此需要重复。 

 在 计算机网络环境中，基于这样重传机制的可靠数据传输协议称为自动重传请求( Automatic Repeal reQuesl, ARQ) 协议。

基本上， ARQ 协议中还需要另外三种协议功能来处理存在比特差错的情况:

- 差错检测：首先，需要一种机制以使接收方检测到何时出现了比特差错。此刻，我们只需知道这些技术要求有额外的比特(除了待发送的初始 数据比特之外的比特)从发送方发送到接收方;这些比特将被汇集在 rdt 2. 0 数据 分组的分组检验和宇段中。
- 接收方反馈：我们的rdt 2.0 协议将从 接收方向发送方回送 ACK 与 NAK 分组。 理论上，这些分组只需要一个比特长; 如用。表示 NAK ，用 1 表示 ACK。 
- 重传：接收方收到有差错的分组时，发送方将重传该分组文。 

![image-20210715225124614](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210715225124614.png)

图 3- 10 说明了表示 rdt 2. 0 的 FSM，该数据传输协议采用了差错检测、肯定确认与否 定确认。

ps：

- 如果对一个事件没有动作，或没 有就事件发生而采取了一个动作，我们将在 横线上方或下方使用符号 A，以分别明确地 表示缺少动作或事件
- FSM 的初始状态用虚 线表示。

在最右边的状态中，发送方协议等待来自接收方的 ACK 或 NAK 分组。 如果收到一个 ACK 分组(图3-10 中符号 rdt_rcv( rcvpkt) && isACK( rcvpkt) 对 应该事件) ，则发送方知道最近发送的分组已被正确接收，因此协议返回到等待来向上层 的数据的状态。 如果收到一个 NAK 分组，该协议重传最后一个分组并等待战收方为响应 重传分组而回送的 ACK 和 NAK。

注意到下列事实很重要:当发送方处于等待 ACK 或 NAK 的状态时，它不能从上层获得更多的数据;这就是说， rdt_send() 事件不可能出现;仅当 接收到 ACK 并离开该状态时才能发生这样的事件。 因此，发送方将不会发送一块新数据 除非发送方确信接收方已正确接收当前分组。 由于这种行为， rdt2.0这样的协议被称为停-等( slop-and-waü) 协议。 

### rdt2.1版本

nlt 2. 1 的 FSM 描述 ， 这是 rdl 2. 0 的修订版。 

rdt2.0存在一个致命的缺陷。 尤其是我 们没有考虑到 ACK 或 NAK 分组受损的可能性! .这里的难点在于，如果一个 ACK 或 NAK 分组受损，发送方 无法知道接收方是否正确接收了上一块发送的数据。

 考虑处理受损 ACK 和 NAK 时的 3 种可能性:

- 对于第一种可能性，考虑在口述报文情况下人可能的做法。 如果说话者不理解来 自接收方回答的 "OK" 或"请重复一遍"，说话者将可能问"你说什么?" (因此 在我们的协议中引人了一种新型发送方到接收方的分组)。接收方则将复述其回 答。 但是如果说话者的"你说什么?"产生了差错，情况又会怎样呢?接收者不明 白那句混淆的话是口述内容的一部分还是一个要求重复上次回答的请求，很可能 回一句"你说什么?" 。 于是，该回答可能含糊不清了。 显然，我们走上了一条困 难重重之路。 
- 第二种可能性是增加足够的检验和 比特，使发送方不仅可以检测差错，还可恢复 差错。 对于会产生差错但不丢失分组的信道，这就可以直接解决问题。 
- 第三种方法是，当发送方收到含糊不清的 ACK 或 NAK 分组时，只需重传当前数 据分组即可。 然而，这种方法在发送方到接收方的信道中引人了冗余分组( duplicate packet) 。 冗余分组的根本困难在于接收方不知道它上次所发送的 ACK 或 NAK 是否被发送方正确地收到。因 此它无法事先知道接收到的分组是新的还是一次重传 !

**解决这个新问题的一个简单方法**(几乎所有现有的数据传输协议中，包括 TCP，都采 用了这种方法)是在数据分组中添加一新字段，让发送方对其数据分组编号，即将发送数 据分组的序号 (sequence number) 放在该字段。 

 对于停等协议这种简单情况， 1 比特序号就足够了，因为它可让 接收方知道发送方是杏正在重传前一个发送分组(接收到的分组序号与最近收到的分组序 号相同) ，或是一个新分组

于是，接收方只需要检查序号即可确定收到的分组是再一次重传。 因为目前我们假 定信道不去分组. ACK 和] NAK 分组本身不需要指明它们要确认的分组序号。 发送方知道 所接收到的 ACK 和 NAK 分组(无论是否是含糊不清的)是为响应其最近发送的数据分组 而生成的 ）

![image-20210715233649183](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210715233649183.png)

![image-20210715233656811](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210715233656811.png)

 rdl 2. 1 的发 送方和提收方 FSM 的状态数都是以前的两倍。 这是因为协议状态此时必须反映出目前 (向发送方)正发送的分组或(在搜收方)希望接收的分组的序号是 0 还是 1 。值得注意 的是，发送或期望接收 0 号分组的状态中的动作与发送或期望接收 l 号分组的状态中的动 作是相似的;唯一的不同是序号处理的方法不同。

### rdt2.2

rdt 2.2 是在有比特差错信道上实现的一个无 NAK 的可靠数据传输协议，

 rdt2. 1 和 rdt2.2 之间的细微变化在于，接收方此时必须包括由一个 ACK 报文所确 认的分组序号(这可以通过在接收方 FSM 中，在 make_pktO 中包括参数 ACK 0 或 ACK 1 来实现) ，发送方此时必须检查接收到的 ACK 报文中被确认的分组序号(这可通过在发送 方 FSM 中，在 isACKO 中包括参数 0 或 1 来实现)。

![image-20210716162315632](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210716162315632.png)

###  rdt 3. 0

经具有比特差错的丢包信道的可靠数据传输: rdt 3. 0  

假定发送方传输一个数据分组，该分组或 者接收方对该分组的 ACK 发生了丢失。 在这两种情况下，发送方都收不到应当到来的接 收方的响应。 如果发送方愿意等待足够长的时间以便确定分组已丢失，则它只需重传该数 据分组即可。 你应该相倍该协议确实有效。 

实中采取的方法是发送方明智地选择一个时间值，以判定可能发生了丢包(尽管不能确 保) 。 如果在这个时间内没有收到 ACK，则重传该分组。 

 注意到如果一个分组经历了一个 特别大的时延，发送方可能会重传该分组，即使该数据分组及其 ACK 都没有丢失。 这就 在发送方到接收方的信道中引人了冗余数据分组( duplicate data packeL) 的可能性。幸运 的是，由 2.2 协议已经有足够的功能(即序号)来处理冗余分组情况。 

从发送方的观点来看，重传是一种万能灵药。 发送方不知道是一个数据分组丢失，还 是一个 ACK 丢失，或者只是该分组或 ACK 过度延时。 在所有这些情况下，动作是同样 的:重传。为了实现基于时间的重传机制，需要一个倒计数定时器(countdown timer) ，在 一个给定的时间量过期后，可中断发送方。 因此，发送方需要能做到:

- 次发送一个分 组(包括第一次分组和重传分组)时，便启动一个定时器。
- 响应定时器中断(采取适 当的动作) 。 
- 终止定时器。 

![image-20210716162922971](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210716162922971.png)

现在我们归纳一下数据传输协议的要点。 在检验和、序号、定时器、肯定和否定确认 分组这些技术中，每种机制都在协议的运行中起到了必不可少的作用。至此，我们得到了 一个可靠数据传输协议!

![image-20210716163650019](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210716163650019.png)

注意到一个分组的接收时间必定迟于一个分组的发送时间， 这是因为发送时延与传播时延之故。 在图 3-16b-d 中，发送方括号部分表明了定时器的 设置时刻以及随后的超时。 因为分组序 号在 0 和 1 之间交替，因此 rclt 3. 0 有时被称为比特交替协议( altemating- bit protoco]) 。

### 流水线操作

![image-20210716165518077](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210716165518077.png)

停等协议的信道利用率低。解决这种特殊的性能问题的一个简单方法是：不使用停等方式运行，允许发送方发送 多个分组而无需等待确认。

 因为许多从发送方向接收方输 送的分组可以被看成是填充到一条流水线中，故这种技术被称为流水线( pipelining) 。 流 水线技术对可靠数据传输协议可带来如下影响:

- 必须增加序号范围，因为每个输送中的分组(不计算重传的)必须有一个唯一的 序号，而且也许有多个在输送中未确认的报文。 
- 协议的发送方和接收方两端也许必须缓存多个分组。 发送方最低限度应当能缓冲 那些已发送但没有确认的分组 3 如下面讨论的那样，接收方或许也需要缓存那些 已正确接收的分组。 
- 所需序号范围和对缓冲的要求取决于数据传输协议如何处理丢失、损坏及延时过 大的分组。 解决流水线的差错恢复有两种基本方法是:回退 N 步 (Go- Back-N， GBN) 和选择重传 (Selective Repeat. SR) 。

### 回退N步协议（Go-Back-N）

在回退 N 步 (GBN) 协议中，允许发送方发送多个分组(当有多个分组可用时)而 不需等待确认，但它也受限于在流水线中未确认的分组数不能超过某个最大允许数 N。

![image-20210717104041614](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210717104041614.png)

图 3-19 显示了发送方看到的 GBN 协议的序号范围。

 如果我们将基序号( base) 定义 为最早的未确认分组的序号，将下一个序号( nextseqnum) 定义为最小的未使用序号(即 下一个待发分组的序号) ，则可将序号范围分割成 4 段。 

- 在 [0 , base - 1] 段内的序号对 应于已经发送并被确认的分组。 
- [ base , nextseqnum - 1 ]段内对应已经发送但未被确认的 分组。
- [ nextseqnum - 1， base + N - 1] 段内的序号能用于那些要被立即发送的分组，如果有 数据来自上层的话。
-  最后，大于或等于 base + N 的序号是不能使用的，直到当前流水线中 未被确认的分组(特别是序号为 base 的分组)已得到确认为止。 

那些已被发送但还未被确认的分组的许可序号范围可以被 看成是一个在序号范围内长度为 N 的窗口 。 随着协议的运行，该窗口在序号空 间向前滑 动。 因此 ， N 常被称为窗口长度 (window size) , GBN 协议也常被称为滑动窗口协议 ( sliding- window protocol) 。 

![image-20210717105719842](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210717105719842.png)



GBN的发送方必须响应三种类型的事件:

1.  当上层调用 rdt_send()时，发送方首先检查发送窗口是否已满，即是 否有 N个已发送但未被确认的分组。 如果窗口未满，则产生一个分组并将其发送， 并相应地更新变量。 如果窗口已满，发送方只需将数据返回给上层，隐式地指示 上层该窗口已满。 然后上层可能会过一会儿再试。 在实际实现中，发送方更可能 缓存(并不立刻发送)这些数据，或者使用同步机制(如一个信号量或标志)允 许上层在仅当窗口不满时才调用 rdt_send() 。 
2. 收到一个 ACK。 在 GBN 协议中，对序号为 n 的分组的确认采取累积确认( cumulative acknowledgment) 的方式，表明接收方已正确接收到序号为n的以前且包括 n 在内的所有分组。 
3. 超时事件。 协议的名字"回退 N 步"来源于出现丢失和时延过长分组时发送方的 行为。 就像在停等协议中那样，定时器将再次用于恢复数据或确认分组的丢失。 如果出现超时，发送方重传所有已发送但还未被确认过的分组。 图 3-20 中的发送 方仅使用一个定时器，它可被当作是最早的已发送但未被确认的分组所使用的定 时器。如果收到一个 ACK ，但仍有已发送但未被确认的分组，则定时器被重新启动。 如果没有已发送但未被确认的分组，该定时器被终止。 

在 GBN 中，接收方的动作也很简单。 如果一个序号为n的分组被正确接收到，并且 按序(即上次交付给上层的数据是序号为 n-1 的分组) ，则接收方为分组 n 发送一个 ACK，并将该分组中的数据部分交付到上层。 在所有其他情况下，接收方丢弃该分组，并 为最近按序接收的分组重新发送 ACK。 注意到因为一次一个交付给上层一个分组，如果分组 k 已接收并交付，则所有序号比 k 小的分组也已经交付。 因此，使用累积确认是 GBN 一个 自然的选择。 

在 GBN 协议中，接收方丢弃所有失序分组。尽管丢弃一个正确接收(但失序)的分 组有点愚蠢和浪费，但这样做是有理由的：

 前面讲过，接收方必须按序将数据交付给上 层。 假定现在期望接收分组 n， 而分组 n+ 1 却到了 。 因为数据必须按序交付，接收方可能 缓存(保存)分组凡+ 1 ，然后，在它收到并交付分组 n 后，再将该分组交付到上层。 然 而，如果分组 n 丢失，则该分组及分组 n + 1 最终将在发送方根据 GBN 重传规则而被重传。 因此，其实接收方没必要缓存n+1，只需丢弃分组 n+1即可。 这种方法的优点是接收缓存简单， 接收方不需要缓存任何失序分组。 因此，虽然发送方必须维护窗口的上下边界及 nextseqnum 在该 窗口中的位置，但是接收方需要维护的唯一信息就是下一个按序接收的分组的序号。 该值保存在 expectedseqnum 变量中

![image-20210717160124291](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210717160124291.png)

图 3-22 给出了窗口长度为 4 个分组的 GBN 协议的运行情况。 因为该窗口长度的限制， 发送方发送分组 0-3 ，然后在继续发送之前，必须等待直到一个或多个分组被确认。 当接 收到每一个连续的 ACK (例如 ACK 0 和 ACK 1) 时，该窗口便向前滑动，发送方便可以 发送新的分组(分别是分组 4 和分组 5) 。 在接收方，分组 2 丢失，因此分组 3 、 4 和 5 被 发现是失序分组并被丢弃。

### 选择重传（Selective Repeat SR）

GBN 本身也有一些情况存在着性能问题。 尤其 是当窗口氏度和带宽时延积都很大时，在流水线中会有很多分组更是如此。 单个分组的差 错就能够引起 GBN 重传大量分组，许多分组根本没有必要重传。 随着信道差错率的增加， 流水线可能会被这些不必要重传的分组所充斥。

![image-20210717160903956](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210717160903956.png)

选择重传 (SR) 协议通过让发送方仅重传那些它怀疑在接收方出错(即 丢失或受损)的分组而避免了不必要的重传。 这种个别的、按需的重传要求接收方逐个地 确认正确接收的分组。 再次用窗口长度 N来限制流水线中未完成、未被确认的分组数。 然而，与 GBN 不同的是，发送方已经收到了对窗口中某些分组的 ACK。 图 3-23 显示了 SR 发送方看到的序号空间。 

SR 发送方的事件与动作：

- 从上层收到j数据。 当从上层接收到数据后， SR 发送方检查下一-个可用于该分组的序号。 如果序号位于发送方的窗口内，则将数据打包并发送;否则就像在 GBN 中一样，要么将数据缓存，要么将其返回给上层以便以后传输。
- 超时。 定时报再次被用来防止丢失分组。 然而，现在每个分组必须拥有其自己的逻辑定时器，因为超时发生后只能发送一个分组。 可以使用单个硬件定时器模拟多个逻辑定时器的操作
- 收到 ACK。 如果收到U ACK，倘若该分组序号在窗口内，则 SR 发送方将那个被确认的分组标记为已接收。 如果该分组的序号等于 send_base ， 则窗口基序号向前移动到具有最小序号的未确认分组处。 如果窗口移动了并且有序号落在窗口内的未发送分组，则发送这些分组。

SR 接收方的事件与动作：

-  序号在[ rcv _base, rcv _base + N - 1]内的分组被正确接收。 在此情况下，收到的分组落在接收方的窗口 内， 一个选择 ACK 被回送给发送方。 如果该分组以前没收到过，则缓存该分组。 如果该分组的序号等于接收窗口 的基序号(图 3-23 中的 rcv_base) ，则该分组以及以前缓存的序号连续的(起始于 rcv_base 的)分组交付给上层。 然后，接收窗口接向前移动分组的编号向上交付这些分组。 举例子来说，考虑一下阁 3-26。 当收到一个序号为 rcv_base =2的分组时，该分组及分组 3 、 4 、 5 可被交付给上层。 
-  序号在[ rcv_base - N， rcv _base - 1 ]内的分组被正确收到。 在此情况下，必须产生一个 ACK ，即使该分组是接收方以前已确认过的分组。
-  其他情况。 忽略该分组。

SR 接收方将确认一个正确接收的分组而不管其是否按序。 失序的分组将被缓存直到 所有丢失分组(即序号更小的分组)皆被收到为止，这时才可以将一批分组按序交付给上层。

注意到图 3-25 中的第二步很重要，接收方重新确认(而不是忽略)己收到过的那些 序号小于当前窗口基序号的分组。 你应该理解这种重新确认确实是需要的。 例如，给定在 图 3-23 中所示的发送方和接收方的序号空间，如果分组 send_base 的 ACK 没有从接收方传播回发送方，则发送方最终将重传分组 send_basee ，即使显然(对我们而不是对发送方来 说1)接收方已经收到了该分组。 如果接收方不确认该分组，则发送方窗口将永远不能向 前滑动!这个例子说明了 SR 协议(和很多其他协议一样)的一个重要方面。 对于哪些分 组已经被正确接收，哪些没有，发送方和接收方并不总是能看到相同的结果。 对 SR 协议 而言，这就意味着发送方和接收方的窗口并不总是一致。 

![image-20210717163240579](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210717163240579.png)

图 3-26 给出了一个例子以说明出 现丢包时 SR 的操作。 值得注意的是，在图 3-26 中接收方初始时缓存了分组 3 、 4、 5 ，并 在最终收到分组 2 时，才将它们一并交付给上层。

### 可靠传输机制总结

| 机制         | 用途和说明                                                   |
| ------------ | ------------------------------------------------------------ |
| 检验和       | 用于检测在一个传输分组中的比特错误                           |
| 定时器       | 用于超时/重传一个分组，可能因为该分组(或其 ACK) 在信道中丢失了。 由于当一个分组延时但未丢失(过早超时) ，或当一个分组已被接收方收到但从接收方到发送方的 ACK 丢失时，可 能产生超时事件，所以接收方可能会收到一个分组的多个冗余副本。 |
| 序号         | 用于为从发送方流向接收方的数据分组按顺序编号。 所接收分组的序号间的空隙可使接收方检测出丢失的分组。 具有相同序号的分组可使接收方检测出一个分组的冗余副本 |
| 确认         | 接收方用于告诉发送方一个分组或一组分组已被正确地接收到了。 确认报文通常携带着被确认 的分组或多个分组的序号。 确认可以是逐个的或累权的，这取决于协议 |
| 否定确认     | 接收方用于告诉发送方某个分组未被正确地接收。 否定确认报文通常携带着未被正确接收的分 组的序号 |
| 窗口、流水线 | 发送方也许被限制仅发送那些序号落在一个指定范围内的分组。 通过允许一次发送多个分组但 未被确认，发送方的利用率可在停等操作模式的基础上得到增加。 我们很快将会看到，窗口长度可根据接收方接收和缓存报文的能力、网络中的拥塞程度或两者情况来进行设置 |



## TCP协议

 TCP "连接"不是一条像在电路交换网络中的端到端 TDM 或 FDM 电路，也不是 一条虚电路(参见第 1 章) ，因为其连接状态完全保留在两个端系统中。 由于 TCP 协议只 在端系统中运行，而不在中间的网络元素(路由器和链路层交换机)中运行，所以中间的 网络元素不会维持 TCP 连接状态。 

TCP 连接提供的是全双工服务(full-duplex service) 。TCP 连接也总是点对点( point-to-point) 的，即在单个发送 方与单个接收方之间的连接。 不能实现多播

一个 Python 客户程序通过发出下面的命令来实 现此目的。

```
clientSocket.connect((serverName,serverPort))
```

其中 serverName 是服务器的名字， serverPort 标识了服务器上的进程。客户上的 TCP 便开始与服务器上的 TCP 建立一条 TCP 连接。

1. 客户首先发送一个特殊的 TCP 报文段
2. 服务器用 另一个特殊的 TCP 报文段来响应
3. 客户再用第三个特殊报文段作为响应



![image-20210716232329074](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210716232329074.png)

一旦建立起一条 TCP 连接，两个应用进程之间就可以相互发送数据了。我们考虑一下 从客户进程向服务器进程发送数据的情况。

客户进程通过套接字(该进 程之门)传递数据流。 数据一旦通过该门，它就由客户中运行的 TCP 控制了。  TCP 将这些数据引导到该连接的发送缓存 (send buffer) 里，发送缓存是在三次握 手初期设置的缓存之一。 接下来 TCP 就会不时从发送缓存里取出一块数据。 

TCP可从缓存中取出并放入报文段中的数 据数量受限于最大报文段长度 (Maximum Segmenl Size, MSS) 0。MSS 通常根据最初确定的由 本地发送主机发送的最大链路层帧长度(即所谓的最大传输单元 (Maximum Transmission Unit , MTU)) 来设置。设置该 MSS 要保证一个 TCP 报文段(当封装在一个 IP 数据报中) 加上 TCP/IP 首部长度(通常 40 字节)将适合单个链路层帧。 注意到 MSS 是指在报文段里应用层数据的最大长 度，而不是指包括 TCP 首部的 TCP 报文段的最大长度

TCP 连接的组成包括:一台主机上的缓存、变量和与进 程连接的套接字，以及另一台主机上的另一组缓存、变量和与进程连接的套接字。 如前面 讲过的那样，在这两台主机之间的网络元素(路由器、交换机和中继器)中，没有为该连 接分配任何缓存和变量。

### TCP报文段结构

![image-20210716233024115](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210716233024115.png)



 与 UDP 一样，TCP首部包括源端口号和目的端口 号，它被用于多路复用/分解来自或送到上层应用的数据。 另外，同 UDP 一样， TCP 首部也包括检验和字段( cbecksum field) 。 TCP 报文段首部还包含下列字段:

- 32 比特的序号字段 (sequence number field) 和 32 比特的确认号字段( acknowledgment number field) 。 这些字段被 TCP 发送方和接收方用来实现可靠数据传输服务
- 16 比特的接收窗口字段 (receive window field) ，该字段用于流量控制。 该字段用于指示接收方愿意接受的字节数量。
- 可选与变长的选项字段 ( options field) ，该字段用于发送方与接收方协商最大报文 段长度 (MSS) 时，或在高速网络环境下用作窗口调节因子时使用。 首部宇段中还定义了一个时间戳选项。
-  6 比特的标志字段 (flag field) 。 ACK 比特用于指示确认字段中的值是有效的，即 该报文段包括一个对已被成功接收报文段的确认。 RST、 SYN 和 FIN 比特用于连 接建立和拆除，我们将在本节后面讨论该问题。

### 序号和确认号

**序号**

TCP 把数据看成一个无结构的、有序的字节流。 我们从 TCP 对序号的使用上可以看出 这一点，因为序号是建立在传送的字节流之上，而不是建立在传送的报文段的序列之上。 一个报文段的序号 (sequence number for a segment) 因此是该报文段首字节的字节流编号。 

![image-20210716234037856](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210716234037856.png)

假定数据流由一个 包含 500000 字节的文件组成，其 MSS 为 1000 字节，数据流的首字节编号是 0。 如图 3-30 所示，该 TCP 将为该数据流构建 500 个报文段。 给第一个报文段分配序号 0 ，第二个报文 段分配序号 1000 ，第三个报文段分配序号2000。

 我们假设初始序号为 0。 事实上，一条 TCP 连接的双方均可随机地选择 初始序号。 这样做可以减少将那些仍在网络中存在的来自两台主机之间先前已终止的连接 的报文段，误认为是后来这两台主机之间新建连接所产生的有效报文段的可能性(它碰巧 与旧连接使用了相同的端口号)

**确认号**

 TCP 是全双工 的，肉此主机 A 在向主机 B 发送数据的同时，也许也接收来自主机 B 的数据(都是同一 条 TCP 连接的一部分) 。 从主机 B 发出的的每个报文段中都有一个序号用于从 B 流向 A 的数 据。 主机 A 填充进报文段的确认号是主机 A 期望从主机 B 收到的下一字节的序号。

假设主机 A 己收到一个来自主机 B 的包含字节 0-535 的报文段，以 及另一个包含字节 900 -1000 的报文段。 由于某种原因，主机 A 还没有收到字节 536 -899 的报文段。 在这个例子中，主机 A 为了重新构建主机 B 的数据流，仍在等待字节 536 (和 其后的字节) 。 因此， A 到 B 的下一个报文段将在确认号字段中包含 536。 因为 TCP 只确 认该流中至第一个丢失字节为止的字节，所以 TCP 被称为提供累积确认( cumulative acknowledgment) 。

### Talent案例

![image-20210717081553078](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210717081553078.png)

假设客户和服务器的起始序号分别是 42 和 79。

第二个报文段是由服务器发往客户 。 它有两个目的:

- 首先它是为该服务器所收到数据 提供一个确认。 通过在确认号宇段中填人 43 ，服务器告诉客户它已经成功地收到字节 42 及以前的所有字节，现在正等待着宇节 43 的出现。 
- 该报文段的第二个目的是回显字符 ‘ C' 。 因此，在第二个报文段的数据字段里填人的是字符‘ C' 的 ASCII 码。

值得注意的是，对客户到服务器的数据的确认被装载在一 个承载服务器到客户的数据的报文段中;这种确认被称为是被捎带( piggybacked )在服务 器到客户的数据报文段中的。 

### 往返时间的估计和超时

报文段的样本 RTT( 表示为 SampleRTT) 就 是从某报文段被发出(即交给 IP) 到对该报文段的确认被收到之间的时间量。 

为了估计一个典型的RTT啊，自然要采取某种对SampleRTT 取平均的办法。 TCP 维持一个 SampleRTT 均值 (称为 EstimatedRTT) 。 一旦获得一个新 SampleRTT时， TCP 就会根据下列公式来更新 EstimatedRTT：

```
EstimatedRTT = (1 – alpha) • EstimatedRTT + alpha • SampleRTT
```

除了估算 RTT外，测量 RTT的变化也是有价值的。 [RFC 6298] 定义了 RTT 偏差 DevTT，用于估算 SampleRTT一般会偏离 EstimaLedRTT 的程度:

```
DevRTT = (1 – beta) • DevRTT + beta •| SampleRTT – EstimatedRTT |
```



## TCP可靠数据传输

TCP 在lP不可靠的尽力而为服务之上创建了一种可靠数据传输服务 (reliable dala transfer service) 。

在我们前面研发可靠数据传输技术时，曾假定每一个已发送但未被确认的报文段都与 一个定时器相关联，这在概念上是最简单的。 虽然这在理论上很好，但定时器的管理却需 要相当大的开销。 因此，推荐的定时器管理过程 [RFC 6298 ] 仅使用单一的重传定时器， 即使有多个已发送但还未被确认的报文段。 

在本节中描述的 TCP 协议遵循了这种单一定时 器的推荐。

### 简化版本TCP

![image-20210717084139776](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210717084139776.png)

以上代码包含三个事件

- 第一个主要事件从上层应用程序接收数据
- 第二个主要事件是超时。 TCP 通过重传引起超时的报文段来响应超时事件。 然后 TCP 重启定时器。 
- 第三个主要事件是一个来自接收方的确认报文段 (ACK) 的到 达(更确切地说是一个包含了有效 ACK 字段值的报文段) 。 当该事件发生时， TCP 将 ACK 的值 y 与它的变量 SendBase 进行比较。 TCP 状态变量 SendBase 是最早未被确认的字节的序号。 (因此 SendBase -1 是指接收方已正确按序接收到的数据的最后一个字节的序号。)如 前面指出的那样， TCP 采用累积确认，所以 y 确认了字节编号在 y 之前的所有字节都已经收 到。 如果 y>SendBase，则该 ACK 是在确认一个或多个先前未被确认的报文段。 因此发送方 更新它的 SendBase 变量;如果当前有未被确认的报文段， TCP 还要重新启动定时器。

一些例子：

![image-20210717093813533](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210717093813533.png)

第一种情况，主机 A 向主机 B 发送一个报文段。假设该 报文段的序号是 92 ，而且包含 8 字节数据。 在发出该报文段之后，主机 A 等待一个来自 主机 B 的确认号为 100 的报文段。 虽然 A 发出的报文段在主机 B 上被收到，但从主机 B 发往主机 A 的确认报文丢失了 。 在这种情况下，超时事件就会发生，主机 A 会重传相同 的报文段。 当然，当主机 B 收到该重传的报文段时，它将通过序号发现该报文段包含了早 已收到的数据。 因此，主机 B 中的 TCP 将丢弃该重传的报文段中的这些字节。 

![image-20210717170547245](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210717170547245.png)

在第二种情况中，如图 3-35 所示，主机 A 连续发回了两个报文段。 第一个报文段序 号是 92 ，包含 8 字节数据;第二个报文段序号是 100 ，包含 20 字节数据。 假设两个报文段 都完好无损地到达主机 B ，并且主机 B 为每一个报文段分别发送一个确认。 第一个确认报文的确认号是 100 ，第二个确认报文的确认号是 120。 现在假设在超时之前这两个报文段中没有一个确认报文到达主机 A。 当超时事件发生时，主机 A 重传序号 92 的第一个报文 段，并重启定时器。 只要第二个报文段的 ACK 在新的超时发生以前到达，则第二个报文 段将不会被重传。

![image-20210717171017963](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210717171017963.png)

在第三种也是最后一种情况中，假设主机 A 与在第二种情况中完全一样，发送两个报 文段。 第一个报文段的确认报立在网络丢失，但在超时事件发生之前主机 A 收到一个确认 号为 120 的确认报文。 主机 A 因而知道主机 B 已经收到了序号为 119 及之前的所有字节; 所以主机 A 不会重传这两个报文段中的任何 一个。这种情况在阁 3-36 中进行了图示。

### 超时间隔加倍

在定时器时限过期后超时间隔的长度。在这种修改中， 每当超时事件发生时，如前所述， TCP 重传具有最小序号的还未被确认的报文段。只是 每次 TCP 重传时都会将下一次的超时间隔设为先前值的两倍，而不是用从 EstimatedRTT 和 DevRTT推算出的值。

因此，超时间隔在每次重传后会呈指数型增长。 然而，每当定时器在另两个事件(即收到上层应用的数据和收到 ACK) 中的任意一 个启动时， Timeoutlnterval 由最近的 EstimaledRTT 值与 DevRTT 值推算得到。 

### 快速重传

当一个报文段丢失时，这种长的超时周期迫使发送方延迟重传丢失的分组，因而增加了端到端时延。 幸运的是，发送方通常可在超时事件发生之前通过注意所谓冗余 ACK 来较好地检测到丢包情况。

 冗余 ACK (duplicate ACK) 就是再次确认某个报文段的 ACK ，而发送方先前已经收到对读报文段的 确认。 

表 3-2 总结了 TCP 接收方的 ACK 生成策略 [RFC 5681 ] 。 

| 事件                                                         | TCP接收方动作                                                |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 具有说期望序号的按序报文段到达。所有在期望序号及以前的数据都已经被确认 | 延迟的 ACK。 对另一个按序报文段的到达最多等待 500ms。 如果下一个按序报文段在这个时间间隔内没有到达，则发送一个 ACK |
| 具有所期望序号的按序报文段到达。 另一个按序报文段等待ACK传输 | 立即发送单个累积 ACK，以确认两个按序报文段                   |
| 比期望序号大的失序报文段到达。 检测出间隔                    | 立即发送冗余 ACK ，指示下一个期待字节的序号(其为间隔的低端的序号） |
| 能部分或完全填充接收数据间隔的报文段到达                     | 倘若该报文段起始于间隔的低揣，则立即发送 ACK                 |

当 TCP 接收方收到一个具有这样序号的报文段时，即其序号大于下一个所期望的、按序的报文段，它检测到了数据 流中的一个间隔，这就是说有报文段丢失。 这个间隔可能是由于在网络中报文段丢失或重新排序造成的。 因为 TCP 不使用否定确认，所以接收方不能向发送方发回一个显式的否定确认。 相反，它只是对已经接收到的最后一个按序字节数据进行重复确认(即产生一个冗 余 ACK) 即可。

因为发送方经常一个接一个地发送大量的报文段，如果一个报文段丢失，就很可能引起许多一个接一个的冗余 ACK。如果 TCP 发送方接收到对相同数据的 3 个冗余 ACK，它 把这当作一种指示，说明跟在这个已被确认过 3 次的报文段之后的报文段已经丢失。

一旦收到 3 个冗余 ACK ， TCP 就执行快速重传(fast retransmit) [RFC 5681 ] ，即 在该报文段的定时器过期之前重传丢失的报文段。 

![image-20210718103109341](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210718103109341.png)

对于采用快速重传的 TCP，可用下列代 码片段代替图 3-33 中的 ACK 收到事件:

![image-20210718102701567](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210718102701567.png)

总结：

- TCP 确认是 累积式的，正确接收但失序的报文段是不会 被接收方逐个确认的。 因此，如图 3-33 所 示(也可参见图 3-19) ， TCP 发送方仅需维 持已发送过未被确认的字节的最小序号 ( SendBase) 和下一个要发送的字节的序号 ( NextSeqNum) 。 在这种意义下， TCP 看起 来更像一个 GBN 风格的协议。 
-  但是 TCP 和GBN 协议之间有着一些显著的区别。 许多 时间 时间 TCP 实现会将正确接收但失序的报文段缓存 图 3-37 快速重传:在某报文段的定时器过期 起来 

### 流量控制

前面讲过，一条 TCP 连接每一侧主机都为该连接设置了接收缓存。当该 TCP 连接收 到正确、按序的字节后，它就将数据放入接收缓存。 相关联的应用进程会从该缓存中读取数据，但不必是数据刚一到达就立即读取。 事实上，接收方应用也许正忙于其他任务，甚至要过很长时间后才去读取该数据。 如果某应用程序读取数据时相对缓慢，而发送方发送 得太多 、 太快，发送的数据就会很容易地使眩连接的接收缓存溢出。 

TCP 为它的应用程序提供了流量控制服务( flow-control service) 以消除发送方使接收方缓存溢出的可能性。 流量控制因此是一个速度匹配服务，即发送方的发送速率与接收方应用程序的读取速率相匹配。

TCP 通过让发送方维护一个称为接收窗口 (receive window) 的变量来提供流量控制。 通俗地说，接收窗口用于给发送方一个指示一一该接收方还有多少可用的缓存空间。 因为 TCP 是全双工通信，在连接两端的发送方都各自维护一个接收窗口 。 我们在文件传输的情 况下研究接收窗口 。 

 假设主机 A 通过一条 TCP 连接向主机 B 发送一个大文件 主机 B 为 该连接分配了一个接收缓存，并用 RcvBuffer 来表示其大小。 主机 B 上的应用进程不时地 从该缓存中读取数据。 我们定义以下变量:

- LastByteReacd: 主机 B 上的应用进程从缓存读出的数据流的最后一个字节的编号。 
- LastByteRcvd: 从网络中到达的并且已放人主机 B 接收缓存巾的数据流的最后一个 字节的编号。 

```
由于 TCP 不允许已分配的缓存溢出，下式必须成立:
LastByteRcvd – LastByteRead <= RcvBuffer
接收窗口用 rwnd 表示，根据缓存可用空间的数量来设置:
rwnd = RcvBuffer - [LastByteRcvd - LastßyteRead ] 
```

由于该空间是随着时间变化的，所以 rwnd 是动态的。 

![image-20210718105819896](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210718105819896.png)

主机 B 通过把当前的 rwnd 值放入它发给主机 A 的报文段接收 窗口字段中，通知主机 A 它在该连接的缓 存中坯有多少可用空间。

主机 A 轮流跟踪两个变量， LastByteSent 和LastByteAcked ，这两个变量的意义很明显。 注意到这两个变量之间的差LastByteSent - LastByteAcked ，就是主机 A 发送到连接中但未 被确认的数据量。 通过将未确认的数据孟控制在值 rwnd 以内，就可以保证主机 A 不会使 主机 B 的接收缓存溢出。 因此，主机 A 在该连接的整个生命周期须保证:。

```
对于这个方案还存在一个小小的技术问题。 为了理解这一点，假设主机 B 的接收缓 存已经存满，使得 rwnd =0。 在将 rwnd =0 通告给主机 A 之后，还要假设主机 B 没有任何数据要发给主机 A。 此时，考虑会发生什么情况。 因为主机 B 上的应用进程将缓存清 空， TCP 并不向主机 A 发送带有 rwnd 新值的新报文段;事实上 ，TCP 仅当在它有数据或有确认要发时才会发送报文段给主机 A。 这样，主机 A 不可能知道主机 B 的接收缓存 已经有新的空间了，即主机 A 被阻塞而不能再发送数据!为了解决这个问题， TCP 规范 中要求:当主机 B 的接收窗口为 0 时，主机 A 继续发送只有一个字节数据的报文段。 这些报文段将会被接收方确认。 最终缓存将开始清空，并且确认报文里将包含一个非 0 的 nwnd 值。 
```

## TCP连接管理

### 三次握手



![image-20210718111755605](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210718111755605.png)

假设运行 在一台主机(客户)上的一个进程想与另一台主机(服务器)上的一个进程建立一条连接。 客户应用进程首先通知客户 TCP，它想建立一个与服务器上某个进程之间的连接。 客户中的 TCP 会用以下方式与服务器中的 TCP 建立一条 TCP 连接:

1. 第一步:客户端的 TCP 首先向服务器端的 TCP 发送一个特殊的 TCP 报文段。 该报文段中不包含应用层数据。 但是在报文段的首部(参见图 3-29 )中的一个标志位 (即 SYN 比特)被置为 1 。 因此，这个特殊报文段被称为 SYN 报文段。 另外，客 户会随机地选择一个初始序号( client_isn) ，并将此编号放置于该起始的 TCP SYN 报文段的序号字段中。 该报文段会被封装在一个 IP 数据报中，并发送给服务器。
2. 一旦包含 TCP SYN 报文段的 IP 数据报到达服务器主机(假定它的确到达了! ) ，服务器会从该数据报中提取出 TCP SYN 报文段，为该 TCP 连接分配 TCP 缓 存和变量，并向该客户 TCP 发送允许连接的报文段。 这个允许连接的报文段也不包含应用层数据。 但是，在报文段 的首部却包含 3 个重要的信息。 首先， SYN 比特被置为 1。 其次，该 TCP 报文段 首部的确认号字段被置为 client_ isn + 1 。 最后，服务器选择自己的初始序号 (server_isn) ，并将其放置到 TCP 报文段首部的序号宇段中。 这个允许连接的报文 段实际上表明了"我收到了你发起建立连接的 SYN 分组，该分组带有初始序号 client_isn。 我同意建立该连接。 我自己的初始序号是 server_isno" 该允许连接的报 文段有时被称为 SYNACK 报文段 (SYNACK segment) 。
3. 在收到 SYNACK 报文段后 ，客户也要给该连接分配缓存和变量。 客户主机则向服务器发送另外一个报文段;这最后一个报文段对服务器的允许连接的报文段进行了确认(该客户通过将值 server_isn + 1 放置到 TCP 报文段首部的确认字 段中来完成此项工作) 。 因为连接已经建立了，所以该 SYN比特被置为 0。 该三次握手的第三个阶段可以在报文段负载中携带客户到服务器的数据。 

一旦完成这 3 个步骤，客户和服务器主机就可以相互发送包括数据的报文段了。 在以 后每一个报文段中， SYN 比特都将被置为 0。 

### 四次挥手

![image-20210718112418721](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210718112418721.png)

天下没有不散的宴席，对于 TCP 连接也是这样。 参与一条 TCP 连接的两个进程中的 任何一个都能终止该连接。 当连接结束 客户 服务器 后，主机中的"资源" (即缓存和变量) 将被释放。 

 举一个例子，假设某客户打 算关闭连接，如图 3-40 所示。 客户应用 进程发出一个关闭连接命令。 这会引起 客户 TCP 向服务器进程发送一个特殊的 TCP 报文段。 这个特殊的报文段让其首 部中的一个标志位即 FIN 比特(参见 图 3-29) 被设置为 1。 当服务器接收到 该报文段后，就向发送方回送一个确认 报文段。 然后，服务器发送它自己的终 止报文段，其 FIN 比特被置为 1 。最后，该客户对这个服务器的终止报文段进行确认。 此时，在两台主机上用于该连接 的所有资源都被释放了。 

### TCP状态变迁

![image-20210718112514618](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210718112514618.png)

在一个 TCP 连接的生命周期内，运行 在每台主机中的 TCP 协议在各种 TCP 状态 (TCP state) 之间变迁。 

- 客户 TCP 开始时处于 CLOSED (关闭)状态。 客 户的应用程序发起一个新的 TCP 连接。这引起客户中的 TCP 向服务器中的 TCP 发送一个 SYN 报文段。 在发送过 SYN 报文段后，客户 TCP 进入了 SYN_SENT 状态。 当客户 TCP 处在 SYN_SENT 状态时，它等待来自服务器 TCP 的对客户所发报文段进行确认且 SYN 比特被置为 1 的一个报文段。 收到这样一个报文段之后，客户 TCP 进入 ESTABUSHED (已建立)状态。 当处在 ESTABUSHED 状态 时， TCP 客户就能发送和接收包含有效载荷数据(即应用层产生的数据)的 TCP 报文段了。
- 假设客户应用程序决定要关闭该连接。 (注意到服务器也能选择关闭该连接。)这引起 客户 TCP 发送一个带有 FlN比特被置为 1 的 TCP 报文段，并进入 FIN_WAIT_1 状态 当处 在FIN_WAlT_1 状态时，客户 TCP 等待一个来自服务器的带有确认的 TCP 报文段。 当它收到该报文段时.客户 TCP 进入 FIN_WAIT_2 状态。 当处在 FIN_WAIT_2 状态时，客户等待 来自服务器的 FIN 比特被置为 1 的另一个报文段;当收到该报文段后，客户 TCP 对服务器 的报文段进行确认，并进入 TIME_WAit状态。 假定 ACK 丢失， TIME_WAlT 状态使 TCP 客户重传最后的确认报文。 在 TIME_WAIT 状态中所消耗的时间是与具体实现有关的，而 典型的值是 30，1分钟，2 分钟。 经过等待后，连接就正式关闭，客户端所有资源(包 包括口号)将被释放。

我们来考虑当一台主机接收到一个 TCP 报文段，其端口号或源 IP 地址与 该主机上进行中的套接字都不匹配的情况。 例如，假如一台主机接收了具有目的端口 80 的一个 TCP SYN 分组，但该主机在端口 80 不接受连接(即它不在端口 80 上运行 Web 服 务器) 。 则该主机将向源发送一个特殊重置报文段。 该 TCP 报文段将 RST 标志位(参见 3.5.2 节)置为 1 。 因此，当主机发送一个重置报文段时，它告诉该源"我没有那个报文 段的套接字。 请不要再发送该报文段了" 。 当一台主机接收一个 UDP 分组，它的目的端口 与进行中的 UDP 套接字不匹配，该主机发送一个特殊的 ICMP 数据报



## TCP拥塞控制

在最为宽泛的级别上，我们可根据网络层是否为运输层拥塞控制提供了显式帮助，来 区分拥塞控制方法。 

- 将到端拥塞控制： 在端到端拥塞控制方法中，网络层没有为运输层拥塞控制提供显式支持。 即使网络中存在拥塞，端系统也必须通过对网络行为的观察(如分组 丢失与时延)来推断之。 TCP 必须通过端到端的方法 解决拥塞控制，因为 IP 层不会向端系统提供有关网络拥塞的反馈信息。  TCP 报文段的丢失(通过超时或 3 次冗余确认而得知)被认为是网络拥塞的一个迹象， TCP 会相应地减小其窗口长度。 

![image-20210718175030663](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210718175030663.png)

-  网络辅助的拥塞控制 。 在网络辅助的拥塞控制中，网络层构件(即路由器)向发 送方提供关于网络中拥塞状态的显式反馈信息。 这种反馈可以简单地用一个比特 来指示链路中的拥塞情况。 对于网络辅助的拥塞控制，拥塞信息从网络反馈到发送方通常有两种方式，如图 3-49 所示。 直接反馈信息可以由网络路由器发给发送方。 这种方式的通知通常采用了一种阻塞分组 (choke packet) 的形式(主要是说"我拥塞了! " ) 。 第二种形式的通知是，路由器 标记或更新从发送方流向接收方的分组中的某个字段来指示拥塞的产生。 一旦收到一个标记的分组后，接收方就会向发送方通知该网络拥塞指示。 注意到后一种形式的通知至少要 经过一个完整的往返时间。

TCP 所采用的方法是让每一个发送方根据所感知到的网络拥塞程度来限制其能向连接 发送流量的速率。 

**TCP 发送方如何限制它向其连接发送 流量的速率呢?**



 在 3.5 节中我们看到， TCP 连接的每一端都是由一个接收缓存、一个发送缓存和几个变量( LaslByteRead， rwnd 等)组成。 运行在发送方的 TCP 拥塞控制机制跟踪一个额外的变量，即拥塞窗口 (congestion window) 。拥塞窗口表示为 cwnd ，它对一个 TCP 发送方能向网络中发送流量的速率进行了限制。 特别是，在一个发送方中未被确认的数据量不会超过 cwnd 与 rwnd 中的 最小值，即 

```
LastByteSent – LastByteAcked <= min{cwnd, rwnd}
```

下面进行一些假设

- 我们后面假设 TCP 接收缓存足够大，以至可以忽略接收窗口的限制;因此在发送方中未被确认的数据量仅受限于 cwnd。、
- 假设发送方总是有数据要发送，即在拥塞窗口中的所有报文段要被发送。 

上面的约束限制了发送方中未被确认的数据量，因此间接地限制了发送方的发送速率。我们来考虑一个丢包和发送时延均可以忽略不计的连接。因此粗略地讲， 在每个往返时间 (RTT) 的起始点，上面的限制条件允许发送方向该连接发送 cwnd 个字节 的数据，在该 RTT 结束时发送方接收对数据的确认报文。 因此，该发送方的发送速率大概是 cwnd/RTT 字节/秒。 通过调节 cwnd 的位，发送方因此能调整它向连接发送数据的这率。

 **TCP 发送方如何感知从它到目的地之间的路径上存在拥塞呢?** 



 TCP 发送方的"丢包事件"定义为：

- 出现超时
- 收到来自接收方的 3 个冗余 ACK

当出现过度的拥塞时，在沿着这条路径上的一台(或多 台)路由器的缓存会溢出，引起一个数据报(包含一个 TCP 报文段)被丢弃。 丢弃的数 据报接着会引起发送方的丢包事件(要么超时或收到 3 个冗余 ACK) ，发送方就认为在发 送方到接收方的路径上出现了拥塞的指示。 

在网络中没有拥塞的情况：在 TCP 的发送方将收到对于以前未确认报文段的确 认。 如我们将看到的那样， TCP 将这些确认的到达作为一切正常的指示，即在网络上传输 的报文段正被成功地交付给目的地，并使用确认来增加窗口的长度(及其传输速率) 。 注 意到如果确认以相当慢的速率到达(例如，如果该端到端路径具有高时延或包含一段低带 宽链路) ，则该拥塞窗口将以相当慢的速率增加。 在另一方面，如果确认以高速率到达， 则该拥塞窗口将会更为迅速地增大。 因为 TCP 使用确认来触发(或计时)增大它的拥塞 窗口长度， TCP 被说成是自计时( self -clocking) 的。 

**当发送方感知到端到端的拥塞时，采用何种算法来改变其发送速率呢?**



给定调节 cwnd 值以控制发送速率的机制，关键的问题依然存在: TCP 发送方怎样确 定它应当发送的速率呢?

- 一个丢失的报文段表意味着拥塞，因此当丢失报文段时应当降低 TCP 发送方的速 率。 回想在 3.5.4 节中的讨论，对于给定报文段，一个超时事件或四个确认(一 个初始 ACK 和其后的三个冗余 ACK) 被解释为跟随该四个 ACK 的报文段的"丢 包事件"的一种隐含的指示。从拥塞控制的观点看，该问题是 TCP 发送方应当如 何减小它的拥塞窗口长度，即减小其发送速率，以应对这种推测的丢包事件。
- 一个确认报文段指示该网络正在向接收方交付发送方的报文段，因此 ，当对先前未确认报文段的确认到达时，能够增加发送方的速率。 确认的到达被认为是一切顺利的隐含指示，即报文段正从发送方成功地交付给接收方，因此该网络不拥塞。 拥塞窗口长度因此能够增加。 
- 带宽探测 。 给定 ACK 指示源到目的地路径无拥塞，而丢包事件指示路径拥塞， TCP 调节其传输速率的策略是增加其速率以响应到达的 ACK ，除非出现丢包事件， 此时才减小传输速率。  因此，为探测拥塞开始出现的速率， TCP 发送方增加它的 传输速率，从该速率后退，进而再次开始探测，看看拥塞开始速率是否发生了变 化。  注意到 网络中没有明确的拥塞状态信令，即 ACK 和丢包事件充当了隐式信号，并且每个 TCP 发送方根据异步于其他 TCP 发送方的本地信息而行动。

**TCP 拥塞控制算法 (TCP congestion control algorithm)** 

- 慢启动
- 拥塞避免
- 快速恢复

### 慢启动

```
MSS
TCP可从缓存中取出并放入报文段中的数 据数量受限于最大报文段长度 (Maximum Segmenl Size, MSS) 0。MSS 通常根据最初确定的由 本地发送主机发送的最大链路层帧长度(即所谓的最大传输单元 (Maximum Transmission Unit , MTU)) 来设置。设置该 MSS 要保证一个 TCP 报文段(当封装在一个 IP 数据报中) 加上 TCP/IP 首部长度(通常 40 字节)将适合单个链路层帧。 注意到 MSS 是指在报文段里应用层数据的最大长 度，而不是指包括 TCP 首部的 TCP 报文段的最大长度
```

当一条 TCP 连接开始时， cwnd 的值通 常初始置为 一 个 MSS 的较小值，这就使得初始发送速率大约为 MSS/ RTT。 例如，如果 MSS =500 字且RTT=
200ms，则得到的初始发送速率大约只有 120kbps。 

![image-20210718191211042](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210718191211042.png)

由于对 TCP 发送方而言，可用带宽可能比 MSS/RTT 大得多， TCP 发送方希望 迅速找到可用带宽的数量。 因此，在慢启动 (slow -start )状态， cwnd 的值以 1 个 MSS 开 始并且每当传输的报文段首次被确认就增加1个 MSS。 在图 3-51所示的例子中， TCP 向 网络发送第一个报文段并等待一个确认。 当 该确认到达时， TCP 发送方将拥塞窗口增加 一个 MSS ，并发送出两个最大长度的报文 段。 这两个报文段被确认，则发送方对每个 确认报文段将拥塞窗口增加一个 MSS ，使得拥塞窗口变为 4 个 MSS，并这样下去。 这一过程每过一个 RTT，发送速率就翻番。 因此， TCP 发送速率起始慢，但在慢启动阶段 以指数增长。 

但是，何时结束这种指数增长呢?

- 如果存 在一个由超时指示的丢包事件(即拥塞)， TCP 发送方将 cwnd 设置为 1并重新开始慢启动过程。 它还将第二个状态变量的值 ssthresh ( "慢启动阔值"的速记)设置为 cwnd/2 ， 即当检测到拥塞时将 ssthresh 置为拥塞窗口值的一半。
- 慢启动结束的第二种方式是直接与ssthresh的值相关联。 因为当检测到拥塞时 ssthresh设为 cwnd 的值一半，当到达或超过 ssthresh的值时，继续使 cwnd 翻番可能有些鲁莽 。 因此，当 cwnd 的值等于 ssthresh 时， 结束慢启动并且 TCP 转移到拥塞避免模式。 我们将会看到，当进入拥塞避免模式时， TCP 更为谨慎地增加 cwnd。 
- 最后一种结束慢启动的方式是，如果检测到 3 个冗余 ACK ， 这时 TCP 执行一种快速重传(参见 3.5.4 节)并进入快速恢复状态，后面将讨论相关 内容。 



### 拥塞避免

一旦进入拥塞避免状态， cwnd 的值大约是上次遇到拥塞时的值的一半， 即距离拥塞 可能并不遥远! 因此，TCP 无法每过一个 RTT 再将 cwnd 的值翻番，而是采用了一种较为 保守的方法，每个 RTT 只将 cwnd 的值增加一个 MSS 。 这能够以几种方式完 成。 一种通用的方法是对于 TCP 发送方无论何时到达一个新的确认，就将 cwnd 增加一个 MSS (MSS/ cwnd )字节。 例如，如果 MSS 是 1460 字节并且 cwnd 是 14600 字节，则在一 个 RTT 内发送 10 个报文段。 每个到达 ACK (假定每个报文段一个 ACK) 增加l/ LOMSS 的拥塞窗口长度，因此在收到对所有 10 个报文段的确认后，拥塞窗口的值将增加了一 个 MSS。 

当出现超时时， TCP 的 拥塞避免算法行为相同。 与慢启动的情况一样， cwnd 的值被设置为 1 个 MSS，当丢包事件 出现时， ssthresh 的值被更新为 cwnd 值的一半。

 然而，前面讲过丢包事件也能由一个三个 冗余 ACK 事件触发。 在这种情况下，网络继续从发送方向接收方交付报文段(就像由收 到冗余 ACK 所指示的那样) 。 因此 TCP 对这种丢包事件的行为，相比于超时指示的丢包， 应当不那么剧烈: TCP 将 cwnd 的值减半(为使测量结果更好，计及已收到的 3 个冗余的 ACK 要加上 3 个 MSS) ，并且当收到 3 个冗余的 ACK ，将 ssthresh 的值记录为 cwnd 的值的 一半。接下来进入快速恢复状态。 



### 快速恢复

在快速恢复中，对于引起 TCP 进入快速恢复状态的缺失报文段，对收到的每个冗余的 ACK, cwnd 的值增加一个 MSS。最终，当对丢失报文段的一个 ACK 到达时， TCP 在降低 cwnd 后进入拥塞避免状态。 如果出现超时事件，快速恢复在执行如同在**慢启动**和**拥塞避免**中相同的动作后，迁移到慢启动状态:当丢包事件出现时， cwnd 的值被设置为 1 个 MSS，并且 ssthresh 的值设置为 cwnd 值的一半。 

![image-20210718192609740](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210718192609740.png)

# 网络层

在本章中，我们将对网络层的转发 (forwarding) 功能和路由选择( routing) 功能做重要区分。转发涉及分组在单一的路由器中从一条入链路到一条出链路的传送。 路由选择涉及一个网络的所有路由器，它们经路由选择协议共同交互，以决定分组从源到目的地结点 所采用的路径。

-  转发是指将分组从一个输入链路接口转移到适当的输出链 路接口的路由器本地动作。
-  路由选择是指网络范围的过程，以决定分组从源到目的地所采 取的端到端路径。

 我们将约定术语：分组交换机是指一台通用分组交换设备，它根据分组首部字段 中的值，从输入链路接口到输出链路接口转移分组。 

-  某些分组交换机称为链路层交换机 (link-Iayer switches) (在第 5 章仔细学习) ，基于链路层字段中的值做转发决定
- 其他分 组交换机称为路由器( router) ，基于网络层字段中的值做转发决定。 

因特网的网络层提供了单一的服务，称为尽力而为服务 (best- effort service) 。 



**数据报网络**：在数据报网络中，每当一个端系统要发送分组，它就为该分组加上目的端系统的地址，然后将分组推进网络中。 当分组从源到目的地传输，它通过一系列路由器传递。 这些路由器中的每台都使用分组的目的地址来转发该分组。 特别是，每台路由器有一个将目的地址映射到链路接口的转发表;当分组到达路由器时，路由器使用该分组的目的地址在转发表中查找适当的输出链 路接口 。 然后路由器有意将分组向该输出链路接口转发。 

## 路由器工作原理

![image-20210719224221751](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210719224221751.png)

### 输入端口

![image-20210719224945892](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210719224945892.png)

在输入端口中执行的查找对于路由器的运行是至关重要的。 正是在这个地方，路由器使用转发表来查找输出端口使得到达的分组将能经过交换结构转发到该输出端口 。 转发表是由路由选择处理器计算和更新的，但转发表的一份影子副本通常会被存放在每个输入端口 。 转发表从路由选择处理器经过独立总线(例如一个 PCI 总线)复制到线路卡，在图 4-6 中该总线由从路由选 择处理器到输人线路卡的虚线所指示。 有了影子副本，转发决策能在每个输入端口本地做 出，无须调用中央路由选择处理器，因此避免了集中式处理的瓶颈。

### 输出端口

![image-20210719225428477](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210719225428477.png)

## 因特网中的转发和编址

![image-20210719230000634](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210719230000634.png)

过网络层分组被称为数据报。 

![image-20210719231055188](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210719231055188.png)

- 版本(号) ：这 4 比特规定了数据报的 IP 协议版本，有两种版本 IPV4 与IPV6。通过查看版本号，路由器能 够确定如何解释IP数据报的剩余部分。
- 标识、标志、片偏移。 这三个字段与所谓 IP分片有关，这是一个我们将很快要深 人考虑的一个问题。 有趣的是，新版本的 IP( 即 IPv6) 不允许在路由器上对分组 分片。 
- 数据(有效载荷) 。 我们来看看最后的也是最重要的字段，这是数据报存在的首要 理由!在大多数情况下， IP 数据报中的数据字段包含要交付给目的地的运输层报 文段 (TCP 或 UDP) 。 然而，该数据宇段也可承载其他类型的数据，如 ICMP 报文 。
- 源和目的 IP地址。当某源生成一个数据报时，它在源IP字段中插入它的四地址， 在目的 IP 地址字段中插人其最终目的地的地址。 通常源主机通过 DNS 查找来决定 目的地址

### IP数据报分片

并不是所有链路层协议都能承载相同长度的网络层分组。 有 的协议能承载大数据报，而有的协议只能承载小分组。一个链路层帧能 承载的最大数据量叫做最大传送单元( Maximum Transmission Unit , MTU) 。因为每个 F 数 据报封装在链路层帧中从一台路由器传输到下一台路由器，故链路层协议的 MTU 严格地 限制着 E 数据报的氏度。 对 E 数据报氏度具有严格限制并不是主要问题。 问题在于在发 送方与目的地路径上的每段链路可能使用不同的链路层协议，且每种协议可能具有不同 的 MTU。

想象你是一台互联几条链路的路由器，且每条链路运行具有不同 MTU 的链路层协议。 假定你从某条链路收到一个 IP数据报，通过检查转发表 确定出链路，并且该出链路的 MTU 比该 IP数据报的长度要小。 此时你会感到慌乱，如何 将这个过大的 IP 分组压缩进链路层帧的有效载荷字段呢?

解决该问题的方法是将 IP数据 报中的数据分片成两个或更多个较小的 IP数据报，用单独的链路层帧封装这些较小的 IP数据报;然后向输出链路上发送这些帧。 每个这些较小的数据报都称为片( fragment) 。 

为坚持网络内核保持简单的原则， IP叫的设计者决定将数据报的重新组装工作放到端系统中，而不是放到网络路由器中 。

当一台目的主机从相同源收到一系列数据报时，它需要确定这些数据报中的某些是否 是一些原来较大的数据报的片。 如果某些数据报是片的话，则它必须进一步确定何时收到 了最后一片，并且如何将这些接收到的片拼接到一起以形成初始的数据报。 

为了让目的主 机执行这些重新组装任务， IPv4 的设计者将标识、标志和片偏移字段放在 E 数据报首部 中。 当生成一个数据报时，发送主机在为该数据报设置源和目的地址的同时再贴上标识号。 

- 发送主机通常将为它发送的每个数据报的标识号加 1。 
- 当某路由器需要对一个数据报分片时，形成的每个数据报(即片)具有初始数据报的源地址、目的地址与标识号。 
- 当目 的地从同一发送主机收到一系列数据报时，它能够检查数据报的标识号以确定哪些数据报 实际上是同一较大数据报的片。 
- 由于 lP 是一种不可靠的服务，一个或多个片可能永远到 达不了目的地。 因为这种原因，为了让目的主机绝对地相信它已收到了初始数据报的最后 一个片，最后一个片的标志比特被设为 0 ，而所有其他片的标志比特被设为 1。
- 另外，为 了让目的主机确定是再丢失了一个片(且能按正确的顺序重新组装片) ，使用偏移字段指 定该片应放在初始IP 数据报的哪个位置。

![image-20210720194802213](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210720194802213.png)

在目的地，数据报的有效载荷仅当在 E 层己完全重构为初始IP 数据报时，才被传递 给目的地运输层。如果一个或多个片没有到达目的地，则该不完整的数据报被丢弃且不会交给运输层。 但是，如我们在前一章知道的那样、若在运输层正使用着 TCP，则 TCP 将通 过让源以初始数据报来重传数据，以恢复这次丢包。 

### IPV4编址

当主机中的IP 想发送一个数据报时，它就在该链路 上发送。 主机与物理链路之间的边界叫做接口( interface) 。 

每个 IP 地址长度为 32 比特(等价为 4 字节) ，因此总共有 2^32个可能的 IP 地址。

在全球因特网中的每台主机和路由器上的每个接口，必须有一个全球唯一的lP地址。然而，这些地址不能随意地自由选择。一 个接口的 E 地址的一部分需要由其连接的子网来决定。 

因特网的地址分配策略被称为无类别域间路由选择 (Classless lnterdomain Routing , CIDR)。CIDR 将子网寻址的概念一般化了。因为对于子网寻址， 32 比特的 IP 地址被划分为两部分，并且也具有点分十进制数形式 α. b. c. d/x ， 其中 x 指示了地址的 第一部分中的比特数。

形式为 α. b. c. d/x 的地址的 x 最高比特构成了 IP 地址的网络部分，并且经常被称为该 地址的前缀( prefix) (或网络前缀) 。 一个组织通常被分配一块连续的地址， 即具有相同前缀的一段地址 。 在这种情况下，该组织内部的设备的IP地址将共享共同的前缀。 

一个地址的剩余 32 - x 比特可认为是用于区分该组织内部设备的，其中的所有设备具 有相同的网络前缀。 当该组织内部的路由器转发分组时，才会考虑这些比特。 

### 因特网控制报文协议

ICMP 由定义，被主机和路由器用来彼此沟通网络层的信息。 ICMP 最典型的用途是差错报告。 ICMP 通常被认为是 IP 的一部分，但从体系结构上讲它是位于 IP 之上的，因为 ICMP 报文是承载在IP分组中的。这就是说， lCMP 报文是作为 IP 有效载荷承载的，就像 TCP 与 UDP 报文段作为 IP 有效载荷被承载那样。 类似地，当一台主机收到一个指明上层协议 为 ICMP 的 IP 数据报时，它分解出该数据报的内容给 ICMP，就像分解出一个数据报的内 容给 TCP 或 UDP 一样。

ICMP 报文有一个类型字段和一个编码字段，并且包含引起该 ICMP 报文首次生成的 IP 数据报的首部和前 8 字节内容(以便发送方能确定引发该差错的数据报)。 

![image-20210720202402216](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210720202402216.png)

众所周知的 ping 程序发送一个 ICMP 类型 8 编码 0 的报文到指定主机。看到该回显 ( echo) 请求，目的主机发回一个类型 0 编码。的 ICMP 回显回答。

### IPv6

![image-20210720203322025](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210720203322025.png)

# 网络安全

## 加密方式

![img](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/v2-b6323d4fcd035e3c1b6e3aaae3371956_720w.jpg)

**对称秘钥加密：**

加密和解密同用一个秘钥的方式称为共享秘钥加密。存在的问题是加密方要将秘钥安全的发送给解密方

![img](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/v2-aed72c7edd15d5056bf2ca543fb2e781_720w.jpg)

**非对称加密：**

信息接收方一次生成两把秘钥（分别是公钥和私钥），公钥公布在互联网上。

**数字签名：**

当客户端向服务器索要公钥，如何保证公钥不被篡改，是可以信任的？

为了证明接收方公布的公钥不是恶意的，需要借助第三方机构CA，将服务器的公钥放在数字证书（由CA发布），只要证书是可可信的，公钥就是可信的







# 计网知识点提炼



## TCP/IP五层模型介绍

### **应用层：**

应用层专注于为用户提供功能

- DNS：实现网络设备域名到IP地址的映射服务
- HTTP（HyperText Trensfer Protocol）：用于实现Web
- STMP（Simple Mail Transfer Protocol）：用于实现电子邮件的传送服务

它不关心数据是如何传输的。应用层工作在操作系统的用户态，传输层及以下工作在内核态。在Linux内核实现中，链路层协议靠网卡驱动来实现，内核协议栈来实现网络层和传输层。内核对更上层的应用层提供socket接口来供用户进程访问

![不为人知的网络编程(十)：深入操作系统，从内核理解网络包的接收过程(Linux篇)_1.png](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/143659bnw0wdnx617kvndt.png)

### 传输层：

应用层的数据包会传给传输层，传输层为应用层提供两种数据传输服务，分别是TCP和UDP。

TCP协议全称是传输控制协议，它为应用层提供可靠传输服务，能保证数据包完整传输给对方。同时它还拥有流量控制，超时重新传，拥塞控制的其他特点。

UDP协议全称是用户数据报协议，它只负责发送数据包但是不能保证可靠传输。但是相对来说优点就是实时性好。UDP也是可以实现可靠传输的，只要把TCP可靠传输的特性在应用层上进行实现就可以。

TCP协议会对应用层的数据进行分段，每一段的最大大小为MSS，具体数值是在TCP建立连接的时候进行协商的。而UDP协议没有协商能力，不进行数据分段，IP层对使用UDP协议的数据进行分段。

传输层的报文中携带着端口号信息，通过端口号，接收方可以识别传报文的是由哪一个应用接收的。

### 网络层

网络层提供路由和寻址服务。

网络层最经常使用的协议是IP协议（Internet Protocol）, IP会将传输层的报文段加上IP包头组装成IP数据报。如果IP数据报大小超过MTU（MTU ：一般为1500字节，MTU的全称是maximum transmission unit（最大传输单元），MTU可以认为是网络层能够传输的最大IP包）就会再次进行分片。

### 数据链路层和物理层

数据链路层为网络提供链路级别的传输服务。

物理层将数据报转换成电信号使其能够在物理介质中传输。

## HTTP 协议

### HTTP协议是什么

HTTP协议全称是HyperText Transfer Protocol，它是计算机世界中用于服务器和客户端两点之间双向传输超文本数据的约定和规范

### HTTP协议常见状态码

![image-20210728170254042](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210728170254042.png)

**1XX：**

属于提示信息，是协议处理的一种中间状态，很少用到

**2XX：**

表示服务器成功处理了客户端的请求

- 【200 OK】是最常见的成功状态码，表示一切正常。如果是非HEAD请求，服务器返回的响应里有body数据
- 【204 No Content】也是成功状态码，但是响应没有body数据
- 【206 Partial COntent】应用于HTTP分块下载和断点续传，表示返回的body数据不是资源的全部，而是其中一部分。

**3XX：**

表示客户端请求的资源发生了变动，需要客户端用新的URL重新发送请求获取资源，也就是资源重定向

- 【301 Moved Permanently】表示永久重定向，说明请求的资源已经不存在，需改用新的URL再次访问
- 【302 Found】表示临时重定向，说明请求的资源还在，但是暂时要用另一个URL访问

![image-20210728172245865](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210728172245865.png)

301和302都会在响应头里给出Location字段，指明后序跳转的URL，浏览器会自动重新定向到新的URL

**4XX:**

表示客户端发送的报文有误，服务器无法处理

- 【403 Forbidden】表示服务器禁止访问资源
- 【404 Not Found】表示请求的资源在服务器上不存在或者找不到，所以无法提供给客户端
- 【405 Method Not Allowed】客户端使用的请求方法在服务端不被允许，例如一个地址请求使用get但服务端对应地址要求post

**5XX：**

表示客户端你的请求报文正确，但是服务器处理时内部出现错误

- 【500 Not Implemented】表示客户端请求的功能还不支持
- 【503 Service Unavailable】表示服务器繁忙，暂时无法响应客户端



### HTTP协议常见字段

- Host字段：当客户端发送请求时，用来指定服务器域名
- Connection字段：客户端使用此字段要求服务器使用TCP持久连接，以便其他请求的复用。HTTP/1.1版本默认的连接都是持久连接，但为了兼容老版本的HTTP，需要指定Connection首部字段的值为Keep-Alive。
- Accept：客户端在发送请求时表明自己可以接受的数据格式
- Accept-Encoding：客户端在请求时说明自己可以接受哪些压缩方式



- Content-Type字段：用于服务器回应时，告诉客户端回应的数据类型
- Content-Encoding：表示服务器返回的数据使用了什么压缩格式
- Content-Length字段：表示消息数据长度

### GET 与 POST的区别

总体来说

- GET方法的含义是请求从服务器获取资源，这个资源可以是文本，页面，图片等
- POST方法相反，它是向URL指定的资源提交数据，数据放在报文的body里

从安全性来看

- GET方法是不安全的，它将请求的参数拼在URL的最后，从而导致有可能被攻击者窃取
- POST方法把请求的参数放在请求体的Body里，对用户来说是不可见的，更安全

从请求的长度来说

- GET请求有长度限制
- POST请求因为将请求的参数放在消息体里，对数据的长度是没有限制的

### GET和POST方法是安全和幂等的吗？

- 安全：安全方法是指不修改资源的 HTTP 方法。
- 幂等：HTTP 幂等方法是指无论调用多少次都不会有不同结果的 HTTP 方法。

GET方法：安全，幂等

POST方法：不安全，非幂等



### HTTP/1.1特性

**优点：**

总体来说，HTTP最突出的优点是：简单易用，灵活，易扩展，跨平台。这也使得它应用广泛

1. 简单：报文格式简洁，整体分为header和body，在header中使用key-value这种简单的文本结构
2. 灵活易于扩展：HTTP协议里的请求方法，状态码，头字段都允许开发人员自定义。HTTP协议位于应用层，可以通过下层协议的选择变化实现更多功能能够。比如HTTPS就是在HTTP与TCP之间增加了SSL/TLS安全传输层，HTTPS/3甚至把TCP层换成了基于UDP的QUIC
3. 应用广泛，跨平台：各类应用，终端都有使用HTTP协议

**缺点：**

缺点主要在于三点：无状态，明文传输，不安全

- 无状态：无状态不能完全算缺点。无状态的好处是服务器不需要记录状态信息，节省服务器资源。但是这使得一些有关联性的操作时会很麻烦。比如在线购物，每一步都需要验证用户身份。可以使用Cookie技术解决无状态问题。
- 明文传输：不加密的明文传输可以方便调试与阅读，但有信息泄露的风险
- 不安全：无法证明报文完整性，不验证通信双方身份

以上安全问题，可以用HTTPS进行解决，也就是引入SSL/TLS层HTTP

### HTTP/1.1性能

给HTTP协议提供传输服务TCP协议，并使用了【请求-应答】的通信模式，这两点是HTTP协议性能的关键

1. 长连接：HTTP/1.0在定义每发起一次TCP请求，都需要建立一次TCP连接， 因为TCP连接的建立和断开过程开销很大，使得每次通信的开销非常大。这个问题在HTTP/1.1使用长连接的方式解决。只要任意一端没有明确提出断开连接，就会一直保持TCP连接状态
2. 管道网络传输：HTTP/1.1使用的长连接使得管道传输成为了可能。在同一个TCP连接里，只要第一个请求发出了，可以不用等待回应，就可以发送第二个请求，可以减少整体响应时间。但是服务器还是按照顺序回应请求。所以如果前面的请求回应的特别慢，后面的请求就要排队等待，形成队头堵塞
3. 队头堵塞：这是HTTP性能问题的关键，当请求序列的第一个请求因为某种原因阻塞时， 后面所有排队的请求也都被阻塞

### HTTP 与HTTPS有哪些区别

![image-20210729140305135](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210729140305135.png)

1. HTTP的信息是明文传输的，存在安全风险。而HTTPS解决了HTTP的这个不安全缺陷，在TCP和HTTP两层协议之间加入了SSL/TLS安全协议，使得报文能够加密传输
2. HTTP的的连接建立相对简单，TCP三次握手之后就可以进行HTTP报文的传输。而HTTPS在TCP三次握手之后，还需要进行SSL/TLS的握手过程，才可进行加密报文传输
3. HTTP的默认端口号时80，HTTPS的默认端口号时443
4. HTTPS协议需要向CA（Certificate Authority）申请数字证书，来保证服务器的身份是可信的

### HTTPS解决了HTTP的哪些问题？

![image-20210729152035461](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210729152035461.png)

HTTP协议存在以下三种安全问题

- 窃听风险：报文是以明文形式传输，报文在通信链路上可能被截获
- 篡改风险：无法验证报文的完整性，可以通过恶意篡改报文植入垃圾广告
- 冒充风险：通信双方身份不经过验证，有假网站冒充真网站的风险

HTTPS通过在HTTP和TCP这两层协议之间加入SSL/TLS协议，很好的解决上述问题

- 信息加密：通过混合加密的方式，使得信息通过密文传输，解决了窃听风险
- 校验机制：通过摘要算法为数据生成独一无二的【指纹】，用其校验数据的完整性，解决了篡改风险
- 身份证书：将服务器的公钥放入到数字证书中，解决了冒充风险

**混合加密：**

HTTPS采用对称加密和非对称加密结合的【混合加密】的方式

- 在通信建立前采用非对称加密的方式交换【会话秘钥】
- 在通信过程中全部采用对称加密的【会话秘钥】的方式加密明文数据

采用混合加密的原因：

- 在秘钥交换期间，为了保证秘钥交换的安全性，使用运算速度慢但是安全的非对称加密进行秘钥交换
- 在通信过程中，因为已经安全交换了秘钥，这时就使用运算速度快的对称加密

### HTTPS是如何建立连接的，其间交换了什么

SSL/TLS协议基本流程：

1. 客户端向服务器索要并验证服务器的公钥
2. 双方协商生产【会话秘钥】
3. 双方采用【会话秘钥】进行加密通信

具体来说SSl/TLS的握手阶段涉及四次次通信

## DNS

### DNS域名的层级

- 根域名服务器：储存了所有顶级域DNS服务器的信息，比如 .com .cn
- 顶级域名服务器（top-level domain）
- 权威名服务器

客户端只要能够找到任意一台DNS服务器，就可以通过它找到根域DNS服务器，然后再一路顺腾摸瓜找到位于下层的某台目标DNS服务器

### 域名解析的过程

域名解析的过程采用的是分级查询，以浏览器发起的域名解析为例子

1. 首先浏览器先查询自己的域名缓存，如果未命中则访问OS缓存，最后再递归访问DNS服务器。
2. 在递归访问DNS服务器这个流程中，首先客户端将请求发送给本地DNS服务器
3. 本地DNS服务器在收到客户端请求后，首先询问根域名服务器，假设根域名发现这个域名是属于com域，那么根域名服务器就会返回它所管理的com域DNS服务器的IP地址。
4. 接着本机DNS询问com域对应的顶级服务器，它会返回对应的下一级的权威域名服务器的IP地址

最后这样递归的查询到请求里域名所对应的Ip地址







## TCP/UDP协议

### TCP与UDP的区别



| 协议 | 连接                                            | 服务对象              | 可靠性                                      | 拥塞控制、流量控制                                           | 传输方式   | 分片方式                                                     |
| ---- | ----------------------------------------------- | --------------------- | ------------------------------------------- | ------------------------------------------------------------ | ---------- | ------------------------------------------------------------ |
| TCP  | TCP是面向连接的传输协议，传输数据前先要建立连接 | TCP提供的是点对点服务 | TCP协议提供可靠服务                         | TCP有拥塞控制和流量控制机制，保证数据传输的安全性，这对网络整体也是有益的 | 字节流     | TCP数据如果大于MSS大小，会在传输层进行分片。目标主机收到后会在传输层进行组装。中途如果丢失一个分片，只需要重新传输这个分片 |
| UDP  | UDP不需要建立连接，即刻传输数据                 | UDP支持一对多服务     | UDP只提供尽最大努力交付，不保证可靠交付数据 | UDP不提供这两个服务，即使网络拥塞也不影响UDP的发送效率       | 数据报文段 | UDP数据如果大圩MTU，这会在传输层进行分片。                   |



### 为什么TCP头部有【首部长度】字段，而UDP头部没有【首部长度字段】

![image-20210729171709156](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210729171709156.png)

因为TCP有可变长的【选择】字段，而UDP头部长度是不会变化的，只有八个字节（四个字段）。

### TCP的三次握手过程描述

![image-20210729171941606](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210729171941606.png)

首先客户端和服务端都处于closed状态，然后先是服务端主动监听某个端口，处于listen状态

- 第一次握手：客户端发送带有SYN标志的数据包给服务端

客户端随机初始化序列号（client_isn)，将此序号置于TCP首部中序号字段中，同时把SYN标志位置1，表示当前报文为SYN报文。

然后就把该SYN报文发给服务端，表示向服务端发起连接，然后客户端进入SYN_SENT状态

- 第二次握手：客户端发送带有SYN/ACK标志的数据包给客户端

![image-20210729172554362](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210729172554362.png)

服务端收到客户端的SYN报文后，首先服务端自己也初始化一个自己的序列号（server_isn），将此序号填入报文TCP首部字段的序列号字段中，其次在TCP首部的【确认应答号】字段填入client_isn + 1。然后把SYN和ACK标准位置1。最后把报文发给客户端，该报文不包含应用层数据，然后服务端处于SYN-RCVD状态

- 第三次握手：

当客户端收到服务端的报文后，还要向服务端回应最后一个应答报文。首先在序列号填入client_isn+1,确认应答号填入server_isn+1，并把ACK标志位置1。然后把报文发给服务端。这次报文可以携带客户端到服务端的数据。最后客户端就一直处于ESTABLISHED状态。

总结：握手的前两次是不携带数据，而第三次握手可以携带数据。

### 为什么TCP需要三次握手

1. **三次握手的目的是建立可靠的通讯连接，简单来说就是确认双方的发送和接收正常**

- 第一次握手结束：Client什么都不能确认；Server确认Client发送正常，自己接收正常
- 第二次握手结束：Client确认自己发送接收都正常，Server发送接收都正常；Server确认Client发送正常，自己接收正常
- 第三次握手结束：Client确认自己发送接收都正常，Server发送接收正常；Server确认Client发送接收正常，自己发送接收正常



2. **避免旧的连接**：需要三次握手才可以旧的连接重复初始化

因为复杂的网络环境，先发送的数据包可能后到目标主机。当客户端发送多次SYN建立连接的报文，且在网络拥堵的情况下

- 一个旧的SYN报文比最新的SYN报文早到达服务器
- 服务器会根据旧的报文返回SYN+ACK给客户端
- 当客户端收到这个报文后，会根据上下文判断这是一个历史连接，那么客户端就会发送RST报文给服务端表示终止这个旧的连接

如果是两次握手连接，就不能够判断当前连接是否是历史连接，而三次握手可以

3. **同步双方序列号**

序列号在TCP连接中非常重要，第一次握手客户端发送一个带序列号的SYN给服务端，需要服务端在第二次握手回一个带有ACK的应答报文，表示客户端的SYN报文已经被接收，也就是客户端序列号已经被服务端知晓。那么同样，在第三次握手客户端也要回一个ACK报文给服务端，确认服务端的序列号已经被准确接收。

也就是说，如果没有第三次握手，服务端就不能确认自己的序列号被准确接收

4. **避免资源浪费**

如果只有两次握手，当客户端发送的SYN请求连接在网络中堵塞时，因为没有收到服务端的ACK，那么客户端就会发送多个SYN。因为没有上次握手，服务端无法确定客户端使用的是哪一次的连接，只能为所有的SYN请求都创建连接。也就是建立了多个冗余的无效连接，造成了不必要的资源浪费

总结，TCP通过三次握手能够，防止历史连接的建立，避免资源浪费，同步双方序列号



### TCP的四次挥手

双方都可以断开连接

![image-20210730100646619](%E8%AE%A1%E7%BD%91%EF%BC%9A%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B.assets/image-20210730100646619.png)

- 假设客户端打算关闭连接，此时会发送一个TCP首部FIN标志位为1的报文，也就是FIN报文（然后客户端进入FIN_WAIT_1的状态）
- 服务端收到报文后，就像客户端发送ACK应答报文（服务端进入CLOSED_WAIT的状态）
- 客户端收到服务端的ACK报文后（进入该FIN_WAIT_2状态）
- 等服务端处理完数据，就会发送FIN报文给客户端（服务端进入LAST_ACK的状态）
- 客户端收到服务端的FIN报文，也会回应一个ACK应答报文，之后进入TIME_WAIT状态
- 服务器收到客户端的ACK应答报文后，就进入CLOSED状态，至此服务端已经完成连接的关闭
- 客户端经过2MSL的时间后，自动进入CLOSED装填，至此客户端也完成连接的关闭

### 为什么 需要四次挥手而不是三次（服务端的FIN与ACK一同发送）

- 当关闭连接时，客户端向服务端发送FIN时，仅仅代表客户端不再发送数据了，但是还能能够接收数据
- 服务器接收到客户端的FIN报文时，先回一个ACK应答报文，而服务器可能还有数据要处理和发送，等服务端不再附送数据时，才发送IN报文给客户端来标识同意现在关闭连接

从上面的的过程可以知道服务端通常先发送ACK报文，然后等待完成数据的处理和发送后再发送FIN，从而导致是四次握手

### 为什么需要TIME-WAIT状态



### SYN包攻击









